#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ä¼˜åŒ–åçš„åœ°å€åˆ†ç±»
"""

import pandas as pd
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from analysis import TokenFlowAnalyzer

def test_optimized_classification():
    """æµ‹è¯•ä¼˜åŒ–åçš„åœ°å€åˆ†ç±»"""
    print("ğŸ§ª æµ‹è¯•ä¼˜åŒ–åçš„åœ°å€åˆ†ç±»")
    print("=" * 50)
    
    # åŠ è½½æ•°æ®
    analyzer = TokenFlowAnalyzer()
    analyzer.load_data("storage/solscan_data_20250901_142013.json")
    analyzer.analyze_net_flows()
    
    df = analyzer.net_flows_df
    
    # æ£€æŸ¥0æµé‡åˆ†ç±»é—®é¢˜
    zero_flow_marketmakers = df[
        (df['net_tokens'] == 0) & 
        (df['address_type'].str.contains('åšå¸‚å•†|å¥—åˆ©è€…', na=False))
    ]
    
    print(f"ğŸš¨ 0æµé‡è¢«åˆ†ç±»ä¸ºåšå¸‚å•†çš„åœ°å€: {len(zero_flow_marketmakers)} ä¸ª")
    
    # ç»Ÿè®¡å„ç±»å‹åœ°å€æ•°é‡
    print("\nğŸ“Š ä¼˜åŒ–åçš„åœ°å€ç±»å‹ç»Ÿè®¡:")
    type_counts = df['address_type'].value_counts()
    for addr_type, count in type_counts.items():
        print(f"   {addr_type}: {count} ä¸ª")
    
    # æµ‹è¯•çœŸå®äº¤æ˜“åœ°å€è¿‡æ»¤
    real_traders_df = df[df['address'].apply(analyzer._is_real_trader_address)]
    excluded_df = df[~df['address'].apply(analyzer._is_real_trader_address)]
    
    print(f"\nğŸ  æ€»åœ°å€æ•°: {len(df)}")
    print(f"âœ… çœŸå®äº¤æ˜“åœ°å€: {len(real_traders_df)}")
    print(f"âŒ æ’é™¤çš„åœ°å€ (èšåˆå™¨/æ± å­/äº¤æ˜“æ‰€): {len(excluded_df)}")
    
    print("\nğŸ·ï¸ è¢«æ’é™¤çš„åœ°å€:")
    for _, row in excluded_df.iterrows():
        address = row['address']
        label = analyzer.address_labels.get(address, "æ— æ ‡ç­¾")
        print(f"   ğŸ“ {address[:8]}...{address[-6:]} - {label}")
    
    # è®¡ç®—ä¼˜åŒ–åçš„å¹³å‡å€¼
    real_inflow_df = real_traders_df[real_traders_df['net_tokens'] > 0]
    real_outflow_df = real_traders_df[real_traders_df['net_tokens'] < 0]
    
    if len(real_inflow_df) > 0:
        avg_inflow = real_inflow_df['net_tokens'].sum() / len(real_inflow_df)
        print(f"\nğŸ“ˆ çœŸå®äº¤æ˜“åœ°å€å¹³å‡å‡€æµå…¥: {avg_inflow:,.2f} ä»£å¸ (åŸºäº {len(real_inflow_df)} ä¸ªåœ°å€)")
    
    if len(real_outflow_df) > 0:
        avg_outflow = abs(real_outflow_df['net_tokens'].sum()) / len(real_outflow_df)
        print(f"ğŸ“‰ çœŸå®äº¤æ˜“åœ°å€å¹³å‡å‡€æµå‡º: {avg_outflow:,.2f} ä»£å¸ (åŸºäº {len(real_outflow_df)} ä¸ªåœ°å€)")
    
    print("\nâœ… ä¼˜åŒ–æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    test_optimized_classification()
