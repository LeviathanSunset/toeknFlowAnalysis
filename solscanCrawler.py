#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Solscan Token Flow Analysis Tool
ä¸€ä½“åŒ–ä»£å¸æµåŠ¨åˆ†æå·¥å…·

åŠŸèƒ½åŒ…æ‹¬ï¼š
1. Solscan API æ•°æ®çˆ¬å–
2. è‡ªåŠ¨ cf_clearance æ›´æ–°
3. æ•°æ®åˆ†æå’Œè½¬æ¢
4. æ™ºèƒ½é˜²æŠ¤ç»•è¿‡

ä½œè€…: LeviathanSunset
ç‰ˆæœ¬: 2.0.0
"""

import requests
import json
import time
import yaml
import os
import pandas as pd
from datetime import datetime
from pathlib import Path
import urllib3
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class SolscanAnalyzer:
    """Solscan ä»£å¸æµåŠ¨åˆ†æå™¨ - ä¸€ä½“åŒ–å·¥å…·"""
    
    def __init__(self, config_path="settings/config.yaml"):
        self.config_path = config_path
        self.config = self._load_config(config_path)
        self.base_url = self.config['api']['base_url']
        self.session = requests.Session()
        self.cf_clearance_updated = False
        
        # è®¾ç½®ä»£ç†
        if self.config['proxy']['enabled']:
            self.proxies = {
                'http': self.config['proxy']['http'],
                'https': self.config['proxy']['https']
            }
        else:
            self.proxies = {}
        
        # è®¾ç½®é‡è¯•ç­–ç•¥
        retry_config = self.config['retry']
        retry_strategy = Retry(
            total=retry_config['max_retries'],
            backoff_factor=retry_config['backoff_factor'],
            status_forcelist=retry_config['status_codes'],
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)
        
        # è®¾ç½®è¯·æ±‚å¤´å’Œcookies
        self.headers = self._build_headers()
        self.cookies = self._build_cookies()
        
        self.session.headers.update(self.headers)
        self.session.cookies.update(self.cookies)
        if self.proxies:
            self.session.proxies.update(self.proxies)
        
        self.timeout = self.config['api']['timeout']
        
        print("ğŸš€ Solscan ä»£å¸æµåŠ¨åˆ†æå™¨å·²åˆå§‹åŒ–")
        print(f"ğŸ”§ ä»£ç†çŠ¶æ€: {'å¯ç”¨' if self.config['proxy']['enabled'] else 'ç¦ç”¨'}")
        print(f"ğŸ›¡ï¸ è‡ªåŠ¨æ›´æ–°: å¯ç”¨")
    
    def _load_config(self, config_path):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            print(f"âŒ é…ç½®æ–‡ä»¶ {config_path} æœªæ‰¾åˆ°")
            raise
        except yaml.YAMLError as e:
            print(f"âŒ é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
            raise
    
    def _save_config(self):
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_path, 'w', encoding='utf-8') as f:
                yaml.dump(self.config, f, default_flow_style=False, allow_unicode=True)
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def _build_headers(self):
        """æ„å»ºè¯·æ±‚å¤´"""
        headers_config = self.config['headers']
        return {
            'accept': headers_config['accept'],
            'accept-encoding': headers_config['accept_encoding'],
            'accept-language': headers_config['accept_language'],
            'origin': headers_config['origin'],
            'referer': headers_config['referer'],
            'sec-ch-ua': headers_config['sec_ch_ua'],
            'sec-ch-ua-mobile': headers_config['sec_ch_ua_mobile'],
            'sec-ch-ua-platform': headers_config['sec_ch_ua_platform'],
            'sec-fetch-dest': headers_config['sec_fetch_dest'],
            'sec-fetch-mode': headers_config['sec_fetch_mode'],
            'sec-fetch-site': headers_config['sec_fetch_site'],
            'user-agent': headers_config['user_agent']
        }
    
    def _build_cookies(self):
        """æ„å»ºcookies"""
        cookies_config = self.config['cookies']
        return {
            '_ga': cookies_config['_ga'],
            'auth-token': cookies_config['auth_token'],
            'cf_clearance': cookies_config['cf_clearance'],
            '_ga_PS3V7B7KV0': cookies_config['_ga_PS3V7B7KV0']
        }
    
    def _update_cf_clearance_with_selenium(self, token_address=None):
        """ä½¿ç”¨ Selenium è‡ªåŠ¨è·å–æ–°çš„ cf_clearance"""
        try:
            import undetected_chromedriver as uc
            from selenium.webdriver.support.ui import WebDriverWait
            
            print("ğŸ”„ å¯åŠ¨æµè§ˆå™¨è·å–æ–°çš„ cf_clearance...")
            
            # é…ç½®æµè§ˆå™¨é€‰é¡¹
            options = uc.ChromeOptions()
            
            if self.config['proxy']['enabled']:
                proxy = self.config['proxy']['http'].replace('http://', '')
                options.add_argument(f'--proxy-server={proxy}')
            
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-gpu')
            
            # åˆ›å»ºæµè§ˆå™¨å®ä¾‹
            driver = uc.Chrome(options=options)
            
            try:
                # æ ¹æ®æ˜¯å¦æœ‰ä»£å¸åœ°å€ï¼Œé€‰æ‹©è®¿é—®çš„URL
                if token_address:
                    target_url = f"https://solscan.io/token/{token_address}"
                    print(f"ğŸŒ æ­£åœ¨è®¿é—®ä»£å¸é¡µé¢: {target_url}")
                else:
                    target_url = "https://solscan.io/"
                    print("ğŸŒ æ­£åœ¨è®¿é—® solscan.io...")
                
                driver.get(target_url)
                
                # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
                print("â³ ç­‰å¾… Cloudflare éªŒè¯é€šè¿‡...")
                wait = WebDriverWait(driver, 60)
                wait.until(lambda driver: "solscan" in driver.title.lower())
                time.sleep(5)
                
                # è·å– cookies
                cookies = driver.get_cookies()
                cf_clearance = None
                other_cookies = {}
                
                for cookie in cookies:
                    if cookie['name'] == 'cf_clearance':
                        cf_clearance = cookie['value']
                    elif cookie['name'] in ['_ga', '_ga_PS3V7B7KV0']:
                        other_cookies[cookie['name']] = cookie['value']
                
                if cf_clearance:
                    # æ›´æ–°é…ç½®
                    self.config['cookies']['cf_clearance'] = cf_clearance
                    for name, value in other_cookies.items():
                        if name in self.config['cookies']:
                            self.config['cookies'][name] = value
                    
                    self._save_config()
                    
                    # æ›´æ–°å½“å‰ä¼šè¯
                    self.cookies['cf_clearance'] = cf_clearance
                    self.session.cookies.update({'cf_clearance': cf_clearance})
                    for name, value in other_cookies.items():
                        if name in self.cookies:
                            self.cookies[name] = value
                            self.session.cookies.update({name: value})
                    
                    self.cf_clearance_updated = True
                    print(f"âœ… cf_clearance å·²æ›´æ–°: {cf_clearance[:50]}...")
                    return True
                else:
                    print("âŒ æœªè·å–åˆ° cf_clearance")
                    return False
                    
            finally:
                driver.quit()
                
        except ImportError:
            print("âŒ éœ€è¦å®‰è£…ä¾èµ–: pip install undetected-chromedriver selenium")
            return False
        except Exception as e:
            print(f"âŒ Selenium æ›´æ–°å¤±è´¥: {str(e)}")
            return False
    
    def _update_cf_clearance_with_requests(self, token_address=None):
        """ä½¿ç”¨ HTTP è¯·æ±‚å°è¯•è·å–æ–°çš„ cf_clearance"""
        try:
            print("ğŸ”„ å°è¯• HTTP æ–¹å¼è·å– cf_clearance...")
            
            temp_session = requests.Session()
            temp_session.headers.update({
                'User-Agent': self.config['headers']['user_agent'],
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive',
            })
            
            if self.proxies:
                temp_session.proxies.update(self.proxies)
            
            # æ ¹æ®æ˜¯å¦æœ‰ä»£å¸åœ°å€ï¼Œé€‰æ‹©è®¿é—®çš„URL
            if token_address:
                target_url = f"https://solscan.io/token/{token_address}"
                print(f"ğŸŒ HTTPæ–¹å¼è®¿é—®ä»£å¸é¡µé¢: {target_url}")
            else:
                target_url = "https://solscan.io/"
                print("ğŸŒ HTTPæ–¹å¼è®¿é—® solscan.io...")
            
            response = temp_session.get(target_url, timeout=30, verify=False)
            
            if 'cf_clearance' in temp_session.cookies:
                new_cf_clearance = temp_session.cookies['cf_clearance']
                
                self.config['cookies']['cf_clearance'] = new_cf_clearance
                self._save_config()
                
                self.cookies['cf_clearance'] = new_cf_clearance
                self.session.cookies.update({'cf_clearance': new_cf_clearance})
                
                self.cf_clearance_updated = True
                print(f"âœ… HTTP æ–¹å¼æ›´æ–°æˆåŠŸ: {new_cf_clearance[:50]}...")
                return True
            else:
                print("âŒ HTTP æ–¹å¼æ— æ³•è·å– cf_clearance")
                return False
                
        except Exception as e:
            print(f"âŒ HTTP æ›´æ–°å¤±è´¥: {str(e)}")
            return False
    
    def _handle_cloudflare_challenge(self, response, token_address=None):
        """å¤„ç† Cloudflare æŒ‘æˆ˜"""
        if response.status_code == 403 or "cloudflare" in response.text.lower():
            print("ğŸ›¡ï¸ æ£€æµ‹åˆ° Cloudflare é˜²æŠ¤ï¼Œå¼€å§‹è‡ªåŠ¨æ›´æ–°...")
            
            # å°è¯• Selenium æ–¹å¼ï¼Œä¼ é€’ä»£å¸åœ°å€
            if self._update_cf_clearance_with_selenium(token_address):
                return True
            
            # å°è¯• HTTP æ–¹å¼ï¼Œä¼ é€’ä»£å¸åœ°å€
            if self._update_cf_clearance_with_requests(token_address):
                return True
            
            print("âŒ æ‰€æœ‰è‡ªåŠ¨æ›´æ–°æ–¹å¼éƒ½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æ‰‹åŠ¨æ›´æ–°")
            return False
        
        return True
    
    def update_cookies_for_token(self, token_address):
        """
        ä¸ºç‰¹å®šä»£å¸åœ°å€æ›´æ–°cookies
        ç›´æ¥è®¿é—® https://solscan.io/token/[ä»£å¸åœ°å€] æ¥è·å–æœ€æ–°çš„cf_clearance
        
        Args:
            token_address: ä»£å¸åœ°å€
            
        Returns:
            bool: æ›´æ–°æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
        """
        print(f"ğŸ”„ ä¸ºä»£å¸ {token_address} æ›´æ–°cookies...")
        
        # å°è¯• Selenium æ–¹å¼
        if self._update_cf_clearance_with_selenium(token_address):
            print(f"âœ… æˆåŠŸé€šè¿‡ä»£å¸é¡µé¢æ›´æ–°cookies: {token_address}")
            return True
        
        # å°è¯• HTTP æ–¹å¼
        if self._update_cf_clearance_with_requests(token_address):
            print(f"âœ… æˆåŠŸé€šè¿‡ä»£å¸é¡µé¢æ›´æ–°cookies: {token_address}")
            return True
        
        print(f"âŒ æ— æ³•ä¸ºä»£å¸ {token_address} æ›´æ–°cookies")
        return False
    
    def get_token_metadata(self, token_address):
        """
        è·å–ä»£å¸metadataä¿¡æ¯ï¼ˆåŒ…æ‹¬æ€»ä¾›åº”é‡ï¼‰
        
        Args:
            token_address: ä»£å¸åœ°å€
            
        Returns:
            dict: ä»£å¸metadataä¿¡æ¯
        """
        print(f"ğŸ” è·å–ä»£å¸ {token_address} çš„metadata...")
        
        # å°è¯•å¤šä¸ªAPIç«¯ç‚¹
        endpoints = [
            f"{self.base_url}/v2/account?address={token_address}&view_as=token",  # æœ€ä½³ç«¯ç‚¹ - æœ‰å®Œæ•´ä¾›åº”é‡
            f"{self.base_url}/v2/token/meta?address={token_address}",  # å¤‡ç”¨ç«¯ç‚¹
            f"{self.base_url}/token/meta?address={token_address}",     # å¤‡ç”¨ç«¯ç‚¹2
        ]
        
        for endpoint_idx, endpoint in enumerate(endpoints):
            # å¯¹ç¬¬ä¸€ä¸ªç«¯ç‚¹å¤šå°è¯•å‡ æ¬¡ï¼ˆå› ä¸ºå®ƒæœ‰æœ€å®Œæ•´çš„æ•°æ®ï¼‰
            max_retries = 3 if endpoint_idx == 0 else 1
            
            for retry in range(max_retries):
                try:
                    if retry > 0:
                        print(f"ğŸ”„ é‡è¯•ç¬¬ {retry + 1} æ¬¡...")
                        time.sleep(2)  # é‡è¯•å‰ç­‰å¾…2ç§’
                    
                    print(f"ğŸ“¡ å°è¯•ç«¯ç‚¹: {endpoint}")
                    
                    # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„headersï¼ŒåŒ…æ‹¬å¿…è¦çš„cookie
                    headers = self.headers.copy()
                    headers.update({
                        'Accept': 'application/json, text/plain, */*',
                        'Accept-Language': 'en-US,en;q=0.9,zh-HK;q=0.8,zh-CN;q=0.7,zh;q=0.6',
                        'Origin': 'https://solscan.io',
                        'Referer': 'https://solscan.io/',
                        'Sec-Fetch-Dest': 'empty',
                        'Sec-Fetch-Mode': 'cors',
                        'Sec-Fetch-Site': 'same-site'
                    })
                    
                    response = self.session.get(
                        endpoint,
                        headers=headers,
                        timeout=10,  # å¢åŠ è¶…æ—¶æ—¶é—´
                        verify=False
                    )
                    
                    print(f"ğŸ“Š å“åº”çŠ¶æ€: {response.status_code}")
                    
                    if response.status_code == 200:
                        data = response.json()
                        print(f"ğŸ” å“åº”æ•°æ®ç»“æ„: {list(data.keys()) if isinstance(data, dict) else type(data)}")
                        
                        # å¤„ç†ä¸åŒçš„å“åº”æ ¼å¼
                        if isinstance(data, dict):
                            # æ ¼å¼1: {success: true, data: {...}}
                            if data.get('success') and 'data' in data:
                                metadata = data['data']
                            # æ ¼å¼2: ç›´æ¥æ˜¯æ•°æ®å¯¹è±¡
                            else:
                                metadata = data
                                
                            print(f"ğŸ“‹ Metadataå­—æ®µ: {list(metadata.keys()) if isinstance(metadata, dict) else 'N/A'}")
                            
                            # æŸ¥æ‰¾ä¾›åº”é‡ä¿¡æ¯çš„å¤šç§å­—æ®µå
                            supply_fields = [
                                'supply', 'total_supply', 'totalSupply', 'max_supply',
                                'current_supply', 'currentSupply', 'circulating_supply', 
                                'circulatingSupply', 'token_supply', 'tokenSupply'
                            ]
                            
                            total_supply = None
                            
                            # é¦–å…ˆåœ¨é¡¶å±‚æŸ¥æ‰¾
                            for field in supply_fields:
                                if field in metadata:
                                    supply_data = metadata[field]
                                    if isinstance(supply_data, dict):
                                        # å°è¯•ä»åµŒå¥—å¯¹è±¡ä¸­è·å–
                                        for sub_field in ['total', 'current', 'value', 'amount', 'total_supply', 'current_supply']:
                                            if sub_field in supply_data:
                                                total_supply = supply_data[sub_field]
                                                if total_supply:
                                                    print(f"âœ… åœ¨ {field}.{sub_field} æ‰¾åˆ°ä¾›åº”é‡: {total_supply}")
                                                    break
                                    else:
                                        total_supply = supply_data
                                        if total_supply:
                                            print(f"âœ… åœ¨ {field} æ‰¾åˆ°ä¾›åº”é‡: {total_supply}")
                                            break
                            
                            # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œåœ¨æ‰€æœ‰åµŒå¥—å¯¹è±¡ä¸­é€’å½’æŸ¥æ‰¾
                            if not total_supply:
                                def find_supply_recursive(obj, path=""):
                                    if isinstance(obj, dict):
                                        for key, value in obj.items():
                                            current_path = f"{path}.{key}" if path else key
                                            if any(supply_term in key.lower() for supply_term in ['supply', 'total', 'current', 'circulation']):
                                                if isinstance(value, (int, float, str)) and str(value).replace('.','').isdigit():
                                                    return value, current_path
                                            result = find_supply_recursive(value, current_path)
                                            if result[0]:
                                                return result
                                    return None, ""
                                
                                supply_result, supply_path = find_supply_recursive(metadata)
                                if supply_result:
                                    total_supply = supply_result
                                    print(f"âœ… é€’å½’æœç´¢åœ¨ {supply_path} æ‰¾åˆ°ä¾›åº”é‡: {total_supply}")
                            
                            # è·å–å°æ•°ä½ - ä»tokenInfoä¸­è·å–
                            decimals = 0
                            if 'tokenInfo' in metadata and 'decimals' in metadata['tokenInfo']:
                                decimals = metadata['tokenInfo']['decimals']
                            else:
                                decimals = (metadata.get('decimals') or 
                                          metadata.get('decimal') or 
                                          metadata.get('token_decimals') or 0)
                            
                            if total_supply:
                                try:
                                    total_supply = float(total_supply)
                                    decimals = int(decimals)
                                    
                                    # è®¡ç®—å®é™…ä¾›åº”é‡ï¼ˆè€ƒè™‘å°æ•°ä½ï¼‰
                                    actual_supply = total_supply / (10 ** decimals)
                                    
                                    print(f"âœ… ä»£å¸metadataè·å–æˆåŠŸ (ç«¯ç‚¹: {endpoint}):")
                                    print(f"   ğŸ“Š æ€»ä¾›åº”é‡: {total_supply} (åŸå§‹)")
                                    print(f"   ğŸª™ å®é™…ä¾›åº”é‡: {actual_supply:,.2f}")
                                    print(f"   ğŸ”¢ å°æ•°ä½: {decimals}")
                                    
                                    metadata['actual_total_supply'] = actual_supply
                                    metadata['total_supply_raw'] = total_supply
                                    metadata['decimals'] = decimals
                                    return metadata
                                    
                                except (ValueError, TypeError) as e:
                                    print(f"âš ï¸ ä¾›åº”é‡æ•°æ®è§£æå¤±è´¥: {e}")
                                    continue
                            else:
                                print(f"âš ï¸ åœ¨metadataä¸­æœªæ‰¾åˆ°ä¾›åº”é‡å­—æ®µ")
                                print(f"   ğŸ” å®Œæ•´å“åº”: {json.dumps(metadata, indent=2, default=str)[:500]}...")
                                
                        # å¦‚æœè¿™ä¸ªç«¯ç‚¹æ²¡æœ‰ä¾›åº”é‡ä½†æœ‰å…¶ä»–ä¿¡æ¯ï¼Œå¹¶ä¸”æ˜¯ç¬¬ä¸€æ¬¡å°è¯•ï¼Œåˆ™ç»§ç»­é‡è¯•
                        if endpoint_idx == 0 and retry < max_retries - 1:
                            continue
                        
                    elif response.status_code == 304:
                        print("ğŸ“ 304 Not Modified - å†…å®¹æœªæ”¹å˜ï¼Œå¯èƒ½éœ€è¦å¤„ç†ç¼“å­˜")
                        if retry < max_retries - 1:
                            continue
                        else:
                            break
                    elif response.status_code == 403:
                        print("âŒ 403é”™è¯¯ï¼Œå°è¯•æ›´æ–°cf_clearance...")
                        if self._handle_cloudflare_challenge(response, token_address):
                            # é€’å½’é‡è¯•å½“å‰ç«¯ç‚¹
                            return self.get_token_metadata(token_address)
                        break
                    else:
                        print(f"âŒ HTTPé”™è¯¯: {response.status_code}")
                        if hasattr(response, 'text'):
                            print(f"   å“åº”å†…å®¹: {response.text[:200]}...")
                        if retry < max_retries - 1:
                            continue
                        else:
                            break
                        
                except Exception as e:
                    print(f"âŒ ç«¯ç‚¹ {endpoint} è¯·æ±‚å¤±è´¥ (é‡è¯• {retry + 1}/{max_retries}): {str(e)}")
                    if retry < max_retries - 1:
                        continue
                    else:
                            break
        
        print("âŒ æ‰€æœ‰ç«¯ç‚¹éƒ½æ— æ³•è·å–ä»£å¸metadata")
        return None
    
    def get_token_transfers(self, address, page=1, page_size=None, from_time=None, to_time=None, value_filter=None):
        """
        è·å–ä»£å¸è½¬è´¦è®°å½•
        
        Args:
            address: ä»£å¸åœ°å€
            page: é¡µç 
            page_size: æ¯é¡µå¤§å°
            from_time: å¼€å§‹æ—¶é—´æˆ³
            to_time: ç»“æŸæ—¶é—´æˆ³
            value_filter: å€¼ç­›é€‰
        """
        url = f"{self.base_url}/v2/token/transfer"
        
        default_params = self.config['default_params']
        
        params = {
            'address': address,
            'page': page,
            'page_size': page_size or default_params['page_size'],
            'remove_spam': str(default_params['remove_spam']).lower(),
            'exclude_amount_zero': str(default_params['exclude_amount_zero']).lower()
        }
        
        if from_time:
            params['from_time'] = from_time
        if to_time:
            params['to_time'] = to_time
        if value_filter:
            params['value[]'] = value_filter
        
        max_retries = 2
        for attempt in range(max_retries + 1):
            try:
                print(f"ğŸ“¡ è¯·æ±‚ç¬¬ {page} é¡µæ•°æ® (å°è¯• {attempt + 1}/{max_retries + 1})")
                
                response = self.session.get(url, params=params, timeout=self.timeout, verify=False)
                
                # æ£€æŸ¥ Cloudflare æŒ‘æˆ˜
                if response.status_code == 403 or (response.status_code != 200 and "cloudflare" in response.text.lower()):
                    if attempt < max_retries:
                        if self._handle_cloudflare_challenge(response, address):
                            print("ğŸ”„ cf_clearance å·²æ›´æ–°ï¼Œé‡è¯•è¯·æ±‚...")
                            continue
                        else:
                            return None
                    else:
                        print("âŒ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                        return None
                
                if response.status_code == 200:
                    data = response.json()
                    return data
                elif response.status_code == 304:
                    return {"message": "æ•°æ®æœªä¿®æ”¹", "status": 304}
                else:
                    print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
                    if attempt < max_retries:
                        print("ğŸ”„ ç¨åé‡è¯•...")
                        time.sleep(2)
                        continue
                    return None
                    
            except Exception as e:
                print(f"âŒ è¯·æ±‚å¼‚å¸¸: {str(e)}")
                if attempt < max_retries:
                    print("ğŸ”„ ç¨åé‡è¯•...")
                    time.sleep(2)
                    continue
                return None
        
        return None
    
    def crawl_all_data(self, address, from_time=None, to_time=None, value_filter=None, max_pages=None):
        """
        çˆ¬å–æ‰€æœ‰ä»£å¸è½¬è´¦æ•°æ®
        
        Args:
            address: ä»£å¸åœ°å€
            from_time: å¼€å§‹æ—¶é—´æˆ³
            to_time: ç»“æŸæ—¶é—´æˆ³
            value_filter: å€¼ç­›é€‰
            max_pages: æœ€å¤§é¡µæ•°
        
        Returns:
            dict: åŒ…å«æ‰€æœ‰æ•°æ®çš„ç»“æœ
        """
        all_data = []
        all_metadata = {}
        page = 1
        total_records = 0
        failed_pages = []
        
        # è·å–é…ç½®
        pagination_config = self.config.get('pagination', {})
        max_pages = max_pages or pagination_config.get('max_pages', 100)
        delay_between_pages = pagination_config.get('delay_between_pages', 0.5)
        retry_failed_pages = pagination_config.get('retry_failed_pages', 2)
        
        print("ğŸš€ å¼€å§‹æ‰¹é‡çˆ¬å–æ•°æ®...")
        print(f"ğŸ“„ æœ€å¤§é¡µæ•°: {max_pages}")
        print(f"â±ï¸  é¡µé¢å»¶è¿Ÿ: {delay_between_pages}ç§’")
        
        # ğŸ“ˆ é¦–å…ˆè·å–ä»£å¸å…ƒæ•°æ®ï¼ˆåŒ…æ‹¬æ€»ä¾›åº”é‡ï¼‰
        print("\nğŸ“Š æ­£åœ¨è·å–ä»£å¸å…ƒæ•°æ®...")
        token_metadata = self.get_token_metadata(address)
        if token_metadata:
            print("âœ… ä»£å¸å…ƒæ•°æ®è·å–æˆåŠŸ")
            # å°†å…ƒæ•°æ®å­˜å‚¨åˆ°ç»“æœä¸­
            all_metadata.update(token_metadata)
        else:
            print("âš ï¸ ä»£å¸å…ƒæ•°æ®è·å–å¤±è´¥ï¼Œå°†ç»§ç»­çˆ¬å–äº¤æ˜“æ•°æ®")
        
        start_time = datetime.now()
        
        while page <= max_pages:
            print(f"\nğŸ“– æ­£åœ¨çˆ¬å–ç¬¬ {page} é¡µ...")
            
            # é‡è¯•æœºåˆ¶
            page_data = None
            for retry in range(retry_failed_pages + 1):
                if retry > 0:
                    print(f"ğŸ”„ ç¬¬ {page} é¡µé‡è¯• {retry}/{retry_failed_pages}...")
                    time.sleep(delay_between_pages * 2)
                
                page_data = self.get_token_transfers(
                    address=address,
                    page=page,
                    from_time=from_time,
                    to_time=to_time,
                    value_filter=value_filter
                )
                
                if page_data:
                    break
            
            if not page_data:
                print(f"âŒ ç¬¬ {page} é¡µè·å–å¤±è´¥")
                failed_pages.append(page)
                page += 1
                continue
            
            # æ£€æŸ¥æ•°æ®
            if 'data' not in page_data or not page_data['data']:
                print(f"âœ… ç¬¬ {page} é¡µæ— æ›´å¤šæ•°æ®ï¼Œçˆ¬å–å®Œæˆ")
                break
            
            # ç´¯ç§¯æ•°æ®
            current_page_count = len(page_data['data'])
            all_data.extend(page_data['data'])
            total_records += current_page_count
            
            if 'metadata' in page_data:
                all_metadata = page_data['metadata']
            
            print(f"âœ… ç¬¬ {page} é¡µæˆåŠŸï¼Œæœ¬é¡µ {current_page_count} æ¡ï¼Œæ€»è®¡ {total_records} æ¡")
            
            # æ£€æŸ¥æ˜¯å¦æœ€åä¸€é¡µ
            default_page_size = self.config['default_params']['page_size']
            if current_page_count < default_page_size:
                print(f"ğŸ“„ æ•°æ®é‡å°äºé¡µå¤§å°ï¼Œå¯èƒ½æ˜¯æœ€åä¸€é¡µ")
                page += 1
                break
            
            page += 1
            
            # å»¶è¿Ÿ
            if page <= max_pages:
                time.sleep(delay_between_pages)
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        # æ„å»ºç»“æœ
        result = {
            "success": True,
            "total_pages": page - 1,
            "total_records": total_records,
            "failed_pages": failed_pages,
            "data": all_data,
            "metadata": all_metadata,
            "crawl_info": {
                "start_time": start_time.isoformat(),
                "end_time": end_time.isoformat(),
                "duration_seconds": duration,
                "address": address,
                "from_time": from_time,
                "to_time": to_time,
                "value_filter": value_filter,
                "max_pages_limit": max_pages,
                "actual_pages": page - 1,
                "cf_clearance_updated": self.cf_clearance_updated
            }
        }
        
        print(f"\nğŸ‰ çˆ¬å–å®Œæˆï¼")
        print(f"ğŸ“Š æ€»è®¡: {page - 1} é¡µ, {total_records} æ¡è®°å½•")
        print(f"â±ï¸  è€—æ—¶: {duration:.2f} ç§’")
        if failed_pages:
            print(f"âš ï¸ å¤±è´¥é¡µé¢: {failed_pages}")
        if self.cf_clearance_updated:
            print("ğŸ”„ æœ¬æ¬¡çˆ¬å–ä¸­ cf_clearance å·²è‡ªåŠ¨æ›´æ–°")
        
        return result
    
    def analyze_data(self, data):
        """
        åˆ†æä»£å¸è½¬è´¦æ•°æ®
        
        Args:
            data: çˆ¬å–çš„åŸå§‹æ•°æ®
            
        Returns:
            dict: åˆ†æç»“æœ
        """
        if not data or not data.get('data'):
            print("âŒ æ²¡æœ‰æ•°æ®å¯åˆ†æ")
            return None
        
        print("\nğŸ“Š å¼€å§‹åˆ†ææ•°æ®...")
        
        # è½¬æ¢ä¸º DataFrame
        df = pd.DataFrame(data['data'])
        
        # åŸºç¡€ç»Ÿè®¡
        total_transactions = len(df)
        
        # é‡‘é¢ç»Ÿè®¡
        if 'amount' in df.columns:
            df['amount'] = pd.to_numeric(df['amount'], errors='coerce')
            total_amount = df['amount'].sum()
            avg_amount = df['amount'].mean()
            median_amount = df['amount'].median()
            max_amount = df['amount'].max()
            min_amount = df['amount'].min()
        else:
            total_amount = avg_amount = median_amount = max_amount = min_amount = 0
        
        # ä»·å€¼ç»Ÿè®¡
        if 'value' in df.columns:
            df['value'] = pd.to_numeric(df['value'], errors='coerce')
            total_value = df['value'].sum()
            avg_value = df['value'].mean()
            median_value = df['value'].median()
            max_value = df['value'].max()
            min_value = df['value'].min()
        else:
            total_value = avg_value = median_value = max_value = min_value = 0
        
        # æ—¶é—´åˆ†æ
        if 'block_time' in df.columns:
            df['block_time'] = pd.to_datetime(df['block_time'], unit='s', errors='coerce')
            time_range = {
                'start': df['block_time'].min(),
                'end': df['block_time'].max(),
                'span_hours': (df['block_time'].max() - df['block_time'].min()).total_seconds() / 3600
            }
        else:
            time_range = None
        
        # åœ°å€åˆ†æ
        unique_from = df['from_address'].nunique() if 'from_address' in df.columns else 0
        unique_to = df['to_address'].nunique() if 'to_address' in df.columns else 0
        
        # é«˜é¢‘åœ°å€åˆ†æ
        top_senders = df['from_address'].value_counts().head(10).to_dict() if 'from_address' in df.columns else {}
        top_receivers = df['to_address'].value_counts().head(10).to_dict() if 'to_address' in df.columns else {}
        
        # å¤§é¢äº¤æ˜“åˆ†æï¼ˆä»·å€¼è¶…è¿‡å¹³å‡å€¼2å€çš„äº¤æ˜“ï¼‰
        if 'value' in df.columns and df['value'].mean() > 0:
            high_value_threshold = df['value'].mean() * 2
            high_value_txs = df[df['value'] > high_value_threshold]
            high_value_count = len(high_value_txs)
            high_value_total = high_value_txs['value'].sum() if not high_value_txs.empty else 0
        else:
            high_value_count = 0
            high_value_total = 0
        
        # æ„å»ºåˆ†æç»“æœ
        analysis = {
            "summary": {
                "total_transactions": total_transactions,
                "unique_from_addresses": unique_from,
                "unique_to_addresses": unique_to,
                "analysis_time": datetime.now().isoformat()
            },
            "amount_stats": {
                "total": total_amount,
                "average": avg_amount,
                "median": median_amount,
                "max": max_amount,
                "min": min_amount
            },
            "value_stats": {
                "total_usd": total_value,
                "average_usd": avg_value,
                "median_usd": median_value,
                "max_usd": max_value,
                "min_usd": min_value
            },
            "time_analysis": time_range,
            "address_analysis": {
                "top_senders": top_senders,
                "top_receivers": top_receivers
            },
            "high_value_analysis": {
                "count": high_value_count,
                "total_value": high_value_total,
                "percentage": (high_value_count / total_transactions * 100) if total_transactions > 0 else 0
            },
            "raw_data_info": {
                "total_pages": data.get('total_pages', 0),
                "crawl_duration": data.get('crawl_info', {}).get('duration_seconds', 0),
                "cf_updated": data.get('crawl_info', {}).get('cf_clearance_updated', False)
            }
        }
        
        # æ‰“å°åˆ†æç»“æœ
        print("="*60)
        print("ğŸ“ˆ æ•°æ®åˆ†æç»“æœ")
        print("="*60)
        print(f"ğŸ“ æ€»äº¤æ˜“æ•°: {total_transactions:,}")
        print(f"ğŸ“¤ å”¯ä¸€å‘é€åœ°å€: {unique_from:,}")
        print(f"ğŸ“¥ å”¯ä¸€æ¥æ”¶åœ°å€: {unique_to:,}")
        print(f"ğŸ’° æ€»ä»£å¸æ•°é‡: {total_amount:,.2f}")
        print(f"ğŸ’µ æ€»ä»·å€¼: ${total_value:,.2f}")
        print(f"ğŸ“Š å¹³å‡äº¤æ˜“ä»·å€¼: ${avg_value:.2f}")
        print(f"ğŸ“Š ä¸­ä½æ•°äº¤æ˜“ä»·å€¼: ${median_value:.2f}")
        print(f"ğŸ”¥ å¤§é¢äº¤æ˜“æ•°é‡: {high_value_count} ({high_value_count/total_transactions*100:.1f}%)" if total_transactions > 0 else "ğŸ”¥ å¤§é¢äº¤æ˜“æ•°é‡: 0")
        print(f"ğŸ’ å¤§é¢äº¤æ˜“æ€»ä»·å€¼: ${high_value_total:,.2f}")
        
        if time_range:
            print(f"â° æ—¶é—´è·¨åº¦: {time_range['span_hours']:.2f} å°æ—¶")
            print(f"ğŸ• å¼€å§‹æ—¶é—´: {time_range['start']}")
            print(f"ğŸ• ç»“æŸæ—¶é—´: {time_range['end']}")
        
        if top_senders:
            print(f"\nğŸ† æœ€æ´»è·ƒå‘é€åœ°å€ (å‰3å):")
            for i, (addr, count) in enumerate(list(top_senders.items())[:3], 1):
                print(f"   {i}. {addr[:16]}... ({count} ç¬”äº¤æ˜“)")
        
        if top_receivers:
            print(f"\nğŸ¯ æœ€æ´»è·ƒæ¥æ”¶åœ°å€ (å‰3å):")
            for i, (addr, count) in enumerate(list(top_receivers.items())[:3], 1):
                print(f"   {i}. {addr[:16]}... ({count} ç¬”äº¤æ˜“)")
        
        print("="*60)
        
        return analysis
    
    def save_data(self, data, filename=None, include_analysis=True):
        """
        ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶
        
        Args:
            data: è¦ä¿å­˜çš„æ•°æ®
            filename: æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
            include_analysis: æ˜¯å¦åŒ…å«åˆ†æç»“æœ
            
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if not filename:
            storage_config = self.config['storage']
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename_template = storage_config['filename_format']
            filename = os.path.join(
                storage_config['directory'], 
                filename_template.format(timestamp=timestamp)
            )
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        try:
            # å¦‚æœéœ€è¦åŒ…å«åˆ†æç»“æœ
            if include_analysis and data.get('data'):
                analysis = self.analyze_data(data)
                if analysis:
                    data['analysis'] = analysis
            
            # ä¿å­˜ JSON æ–‡ä»¶
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
            
            # åŒæ—¶ä¿å­˜ CSV æ ¼å¼ï¼ˆå¦‚æœæœ‰æ•°æ®ï¼‰
            if data.get('data'):
                csv_filename = filename.replace('.json', '.csv')
                df = pd.DataFrame(data['data'])
                df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
                print(f"âœ… CSV æ ¼å¼å·²ä¿å­˜åˆ°: {csv_filename}")
            
            return filename
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {str(e)}")
            return None
    
    def run_analysis(self, token_address=None, from_time=None, to_time=None, value_filter=None, max_pages=None):
        """
        è¿è¡Œå®Œæ•´çš„åˆ†ææµç¨‹
        
        Args:
            token_address: ä»£å¸åœ°å€ï¼ˆå¯é€‰ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼ï¼‰
            from_time: å¼€å§‹æ—¶é—´æˆ³
            to_time: ç»“æŸæ—¶é—´æˆ³
            value_filter: å€¼ç­›é€‰
            max_pages: æœ€å¤§é¡µæ•°
        """
        # è·å–ä»£å¸ä¿¡æ¯
        if not token_address:
            target_tokens = self.config.get('target_tokens', [])
            if target_tokens:
                token_info = target_tokens[0]
                token_address = token_info['address']
                token_name = token_info.get('name', 'Unknown')
                token_symbol = token_info.get('symbol', 'Unknown')
            else:
                print("âŒ æœªæŒ‡å®šä»£å¸åœ°å€ä¸”é…ç½®æ–‡ä»¶ä¸­æ— é»˜è®¤ä»£å¸")
                return None
        else:
            token_name = "Custom"
            token_symbol = "Custom"
        
        print("ğŸ¯ å¼€å§‹ä»£å¸æµåŠ¨åˆ†æ...")
        print(f"ğŸ“ ä»£å¸åœ°å€: {token_address}")
        print(f"ğŸ·ï¸  ä»£å¸åç§°: {token_name}")
        print(f"ğŸ”¤ ä»£å¸ç¬¦å·: {token_symbol}")
        if from_time:
            print(f"â° å¼€å§‹æ—¶é—´: {datetime.fromtimestamp(from_time)}")
        if to_time:
            print(f"â° ç»“æŸæ—¶é—´: {datetime.fromtimestamp(to_time)}")
        if value_filter:
            print(f"ğŸ’° å€¼ç­›é€‰: >= ${value_filter}")
        print("=" * 60)
        
        # çˆ¬å–æ•°æ®
        data = self.crawl_all_data(
            address=token_address,
            from_time=from_time,
            to_time=to_time,
            value_filter=value_filter,
            max_pages=max_pages
        )
        
        if not data or not data.get('total_records'):
            print("âŒ æœªèƒ½è·å–åˆ°æ•°æ®")
            return None
        
        # ä¿å­˜æ•°æ®ï¼ˆåŒ…å«åˆ†æï¼‰
        print("\nğŸ’¾ æ­£åœ¨ä¿å­˜æ•°æ®å’Œåˆ†æç»“æœ...")
        saved_file = self.save_data(data, include_analysis=True)
        
        if saved_file:
            print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")
            print(f"ğŸ“ ç»“æœæ–‡ä»¶: {saved_file}")
            print(f"ğŸ“Š æ•°æ®è®°å½•: {data['total_records']:,} æ¡")
            print(f"â±ï¸  æ€»è€—æ—¶: {data['crawl_info'].get('duration_seconds', 0):.2f} ç§’")
            
            return {
                'data': data,
                'file': saved_file,
                'success': True
            }
        else:
            print("âŒ ä¿å­˜å¤±è´¥")
            return None

def main():
    """ä¸»å‡½æ•° - è¿è¡Œå®Œæ•´çš„åˆ†ææµç¨‹"""
    print("ğŸŒŸ Solscan Token Flow Analyzer v2.0")
    print("=" * 60)
    
    try:
        # åˆ›å»ºåˆ†æå™¨å®ä¾‹
        analyzer = SolscanAnalyzer()
        
        # è¿è¡Œåˆ†æ
        result = analyzer.run_analysis(
            # å¯ä»¥åœ¨è¿™é‡Œè‡ªå®šä¹‰å‚æ•°
            from_time=1756544400,  # å¯é€‰
            to_time=1756548000,    # å¯é€‰
            value_filter=30,       # å¯é€‰
            max_pages=50          # å¯é€‰
        )
        
        if result and result['success']:
            print("\nğŸŠ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
        else:
            print("\nâŒ åˆ†æå¤±è´¥")
            
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
