#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ä¿®æ”¹åçš„æŒ‡æ ‡è®¡ç®—
"""

import pandas as pd
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from analysis import TokenFlowAnalyzer

def test_metrics():
    """æµ‹è¯•æŒ‡æ ‡è®¡ç®—"""
    print("ğŸ§ª æµ‹è¯•æŒ‡æ ‡è®¡ç®—åŠŸèƒ½")
    print("=" * 50)
    
    # åŠ è½½æ•°æ®
    analyzer = TokenFlowAnalyzer()
    analyzer.load_data("storage/solscan_data_20250901_142013.json")
    
    # è®¡ç®—å‡€æµåŠ¨
    analyzer.analyze_net_flows()
    
    # è·å–å‡€æµåŠ¨æ•°æ®
    df = analyzer.net_flows_df
    
    # è®¡ç®—å…³é”®æŒ‡æ ‡
    total_addresses = len(df)
    net_inflow_addresses = len(df[df['net_tokens'] > 0])
    net_outflow_addresses = len(df[df['net_tokens'] < 0])
    
    # è®¡ç®—å‡€æµå…¥/å‡€æµå…¥åœ°å€æ•°æ¯”ä¾‹å’Œå‡€æµå‡º/å‡€æµå‡ºåœ°å€æ•°æ¯”ä¾‹
    total_inflow_tokens = df[df['net_tokens'] > 0]['net_tokens'].sum()
    total_outflow_tokens = abs(df[df['net_tokens'] < 0]['net_tokens'].sum())
    
    # è®¡ç®—å¹³å‡æ¯ä¸ªå‡€æµå…¥åœ°å€çš„æµå…¥é‡
    avg_inflow_per_address = total_inflow_tokens / net_inflow_addresses if net_inflow_addresses > 0 else 0
    # è®¡ç®—å¹³å‡æ¯ä¸ªå‡€æµå‡ºåœ°å€çš„æµå‡ºé‡
    avg_outflow_per_address = total_outflow_tokens / net_outflow_addresses if net_outflow_addresses > 0 else 0
    
    print(f"ğŸ“Š æ€»åœ°å€æ•°: {total_addresses:,}")
    print(f"ğŸ“ˆ å‡€æµå…¥åœ°å€: {net_inflow_addresses:,} ({net_inflow_addresses/total_addresses*100:.1f}%)")
    print(f"ğŸ“‰ å‡€æµå‡ºåœ°å€: {net_outflow_addresses:,} ({net_outflow_addresses/total_addresses*100:.1f}%)")
    print()
    print(f"ğŸ’° æ€»å‡€æµå…¥ä»£å¸: {total_inflow_tokens:,.2f}")
    print(f"ğŸ’° æ€»å‡€æµå‡ºä»£å¸: {total_outflow_tokens:,.2f}")
    print(f"ğŸ“Š å¹³å‡æ¯ä¸ªå‡€æµå…¥åœ°å€: {avg_inflow_per_address:,.2f} ä»£å¸")
    print(f"ğŸ“Š å¹³å‡æ¯ä¸ªå‡€æµå‡ºåœ°å€: {avg_outflow_per_address:,.2f} ä»£å¸")
    print()
    print("âœ… æŒ‡æ ‡è®¡ç®—å®Œæˆï¼")

if __name__ == "__main__":
    test_metrics()
