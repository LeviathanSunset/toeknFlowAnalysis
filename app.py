#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Solscanä»£å¸æµåŠ¨åˆ†æ - Streamlitå¯è§†åŒ–åº”ç”¨
å±•ç¤ºå„ä¸ªåœ°å€çš„å‡€æµå…¥å’Œå‡€æµå‡ºåˆ†æ

ä½œè€…: LeviathanSunset
ç‰ˆæœ¬: 1.0.0
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
from pathlib import Path
from datetime import datetime
import time
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥è‡ªå®šä¹‰åˆ†ææ¨¡å—
try:
    from analysis import TokenFlowAnalyzer
    from solscanCrawler import SolscanAnalyzer
except ImportError as e:
    st.error(f"æ— æ³•å¯¼å…¥åˆ†ææ¨¡å—: {str(e)}")
    st.error("è¯·ç¡®ä¿ analysis.py å’Œ solscanCrawler.py æ–‡ä»¶å­˜åœ¨")
    st.stop()

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Solscanä»£å¸æµåŠ¨åˆ†æ",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        padding: 1rem;
        background: linear-gradient(90deg, #f0f8ff, #e6f3ff);
        border-radius: 10px;
        border: 2px solid #1f77b4;
    }
    
    .metric-container {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #1f77b4;
        margin: 1rem 0;
    }
    
    .net-inflow {
        color: #28a745;
        font-weight: bold;
    }
    
    .net-outflow {
        color: #dc3545;
        font-weight: bold;
    }
    
    .stDataFrame {
        border: 1px solid #dee2e6;
        border-radius: 5px;
    }
    
    .address-cell {
        font-family: 'Courier New', monospace;
        font-size: 0.9rem;
    }
</style>
""", unsafe_allow_html=True)

class StreamlitTokenFlowApp:
    """Streamlitä»£å¸æµåŠ¨åˆ†æåº”ç”¨"""
    
    def __init__(self):
        self.analyzer = None
        self.data_loaded = False
        self.net_flows_df = None
        
    def initialize_session_state(self):
        """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
        if 'analyzer' not in st.session_state:
            st.session_state.analyzer = None
        if 'data_loaded' not in st.session_state:
            st.session_state.data_loaded = False
        if 'net_flows_df' not in st.session_state:
            st.session_state.net_flows_df = None
        if 'analysis_complete' not in st.session_state:
            st.session_state.analysis_complete = False
        if 'crawl_in_progress' not in st.session_state:
            st.session_state.crawl_in_progress = False
        if 'crawl_config' not in st.session_state:
            st.session_state.crawl_config = {
                'token_address': '5zCETicUCJqJ5Z3wbfFPZqtSpHPYqnggs1wX7ZRpump',
                'max_pages': 50,
                'value_filter': 30,
                'from_time': None,
                'to_time': None
            }
    
    def load_available_data_files(self):
        """è·å–å¯ç”¨çš„æ•°æ®æ–‡ä»¶åˆ—è¡¨"""
        storage_dir = Path("storage")
        if not storage_dir.exists():
            return []
        
        # æŸ¥æ‰¾JSONæ•°æ®æ–‡ä»¶
        json_files = list(storage_dir.glob("solscan_data_*.json"))
        json_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        return [str(f) for f in json_files]
    
    def crawl_new_data(self, config):
        """çˆ¬å–æ–°çš„ä»£å¸æ•°æ®"""
        try:
            # åˆå§‹åŒ–çˆ¬è™«
            crawler = SolscanAnalyzer()
            
            # è®¾ç½®è¿›åº¦æ˜¾ç¤º
            progress_container = st.empty()
            status_container = st.empty()
            
            with progress_container.container():
                progress_bar = st.progress(0)
                
            status_container.info("ğŸš€ æ­£åœ¨åˆå§‹åŒ–çˆ¬è™«...")
            progress_bar.progress(10)
            
            # å¼€å§‹çˆ¬å–
            status_container.info(f"ğŸ“¡ æ­£åœ¨çˆ¬å–ä»£å¸æ•°æ®: {config['token_address'][:16]}...")
            progress_bar.progress(30)
            
            # è°ƒç”¨çˆ¬å–æ–¹æ³•
            result = crawler.crawl_all_data(
                address=config['token_address'],
                from_time=config.get('from_time'),
                to_time=config.get('to_time'),
                value_filter=config.get('value_filter'),
                max_pages=config.get('max_pages', 50)
            )
            
            progress_bar.progress(70)
            status_container.info("ğŸ’¾ æ­£åœ¨ä¿å­˜æ•°æ®...")
            
            if result and result.get('success'):
                # ä¿å­˜æ•°æ®
                saved_file = crawler.save_data(result, include_analysis=False)
                
                progress_bar.progress(100)
                status_container.success(f"âœ… çˆ¬å–å®Œæˆï¼è·å¾— {result.get('total_records', 0)} æ¡è®°å½•")
                
                time.sleep(1)
                progress_container.empty()
                status_container.empty()
                
                return saved_file
            else:
                status_container.error("âŒ çˆ¬å–å¤±è´¥")
                return None
                
        except Exception as e:
            st.error(f"çˆ¬å–è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            return None
    
    def format_address(self, address, length=16, analyzer=None):
        """æ ¼å¼åŒ–åœ°å€æ˜¾ç¤ºï¼Œä¼˜å…ˆæ˜¾ç¤ºæ ‡ç­¾å"""
        if pd.isna(address) or not address:
            return "N/A"
        
        # è·å–åˆ†æå™¨å®ä¾‹
        current_analyzer = analyzer or getattr(self, 'analyzer', None) or st.session_state.get('analyzer', None)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åœ°å€æ ‡ç­¾
        if current_analyzer and hasattr(current_analyzer, 'address_labels') and address in current_analyzer.address_labels:
            label = current_analyzer.address_labels[address]
            if len(label) <= length + 5:  # åœ°å€æ ‡ç­¾å¯ä»¥ç¨å¾®é•¿ä¸€ç‚¹
                return label
            else:
                return label[:length] + "..."
        
        # æ²¡æœ‰æ ‡ç­¾æ—¶æ˜¾ç¤ºå‰4ä½å’Œå4ä½
        if len(address) <= 8:
            return address
        return f"{address[:4]}...{address[-4:]}"
    
    def format_currency(self, value):
        """æ ¼å¼åŒ–è´§å¸æ˜¾ç¤º"""
        if pd.isna(value):
            return "$0.00"
        return f"${value:,.2f}"
    
    def format_tokens(self, value):
        """æ ¼å¼åŒ–ä»£å¸æ•°é‡æ˜¾ç¤º"""
        if pd.isna(value):
            return "0"
        
        # æ ¹æ®æ•°é‡å¤§å°é€‰æ‹©æ˜¾ç¤ºæ ¼å¼
        if abs(value) >= 1_000_000:
            return f"{value/1_000_000:,.2f}M"
        elif abs(value) >= 1_000:
            return f"{value/1_000:,.2f}K"
        elif abs(value) >= 1:
            return f"{value:,.2f}"
        else:
            return f"{value:.6f}"
    
    def render_address_copy_buttons(self, df, section_id="default"):
        """æ¸²æŸ“æŒ‰åœ°å€ç±»å‹å¤åˆ¶æŒ‰é’®"""
        # æ ¹æ®section_idæ˜¾ç¤ºä¸åŒçš„æ ‡é¢˜å’Œè¯´æ˜
        if section_id == "chart_section":
            st.markdown("#### ğŸ¥§ é¥¼å›¾åœ°å€å¤åˆ¶")
            st.info("ğŸ“Š åŸºäºé¥¼å›¾æ˜¾ç¤ºçš„æ‰€æœ‰åœ°å€ç±»å‹ï¼Œç‚¹å‡»æŒ‰é’®å¤åˆ¶å¯¹åº”ç±»å‹çš„åœ°å€")
        elif section_id == "table_section":
            st.markdown("#### ğŸ“Š è¡¨æ ¼åœ°å€å¤åˆ¶")
            st.info("ğŸ“‹ åŸºäºå½“å‰ç­›é€‰æ¡ä»¶çš„æ•°æ®è¡¨ï¼Œæ”¯æŒæŒ‰ç±»å‹å’Œæ¡ä»¶å¤åˆ¶åœ°å€")
        else:
            st.markdown("#### ğŸ“‹ ä¸€é”®å¤åˆ¶åœ°å€")
        
        # ç»Ÿè®¡å„ç±»å‹åœ°å€æ•°é‡
        type_counts = df['address_type'].value_counts()
        
        if len(type_counts) == 0:
            st.info("æš‚æ— åœ°å€æ•°æ®")
            return
        
        # åˆ›å»ºåˆ—å¸ƒå±€ï¼Œæ¯è¡Œæœ€å¤š4ä¸ªæŒ‰é’®
        cols_per_row = 4
        rows = (len(type_counts) + cols_per_row - 1) // cols_per_row
        
        for row in range(rows):
            cols = st.columns(cols_per_row)
            for col_idx in range(cols_per_row):
                item_idx = row * cols_per_row + col_idx
                if item_idx < len(type_counts):
                    address_type = type_counts.index[item_idx]
                    count = type_counts.iloc[item_idx]
                    
                    with cols[col_idx]:
                        # è·å–è¯¥ç±»å‹çš„æ‰€æœ‰åœ°å€
                        addresses = df[df['address_type'] == address_type]['address'].tolist()
                        addresses_text = '\n'.join(addresses)
                        
                        # åˆ›å»ºå¤åˆ¶æŒ‰é’®ï¼Œä½¿ç”¨æ›´å”¯ä¸€çš„key
                        button_label = f"{address_type}\n({count}ä¸ª)"
                        unique_key = f"copy_{section_id}_{address_type}_{item_idx}"
                        if st.button(
                            button_label,
                            key=unique_key,
                            help=f"ç‚¹å‡»å¤åˆ¶æ‰€æœ‰{address_type}ç±»å‹çš„åœ°å€",
                            type="secondary"
                        ):
                            # ä½¿ç”¨st.codeæ˜¾ç¤ºå¯å¤åˆ¶çš„æ–‡æœ¬
                            st.code(addresses_text, language=None)
                            st.success(f"âœ… å·²æ˜¾ç¤º {count} ä¸ª{address_type}åœ°å€ï¼Œå¯ä»¥é€‰ä¸­å¤åˆ¶")
        
        # æ·»åŠ å…¨éƒ¨åœ°å€å¤åˆ¶æŒ‰é’®
        st.markdown("---")
        
        if section_id == "chart_section":
            # é¥¼å›¾åŒºåŸŸçš„ç‰¹æ®ŠæŒ‰é’®
            col1, col2, col3 = st.columns([1, 1, 1])
            
            with col1:
                if st.button("ğŸ“‹ å¤åˆ¶å…¨éƒ¨åœ°å€", key=f"copy_all_{section_id}", type="primary"):
                    all_addresses = df['address'].unique().tolist()
                    addresses_text = '\n'.join(all_addresses)
                    st.code(addresses_text, language=None)
                    st.success(f"âœ… å·²æ˜¾ç¤ºå…¨éƒ¨ {len(all_addresses)} ä¸ªåœ°å€")
            
            with col2:
                if st.button("ğŸ” å¤åˆ¶æ’åå‰10", key=f"copy_top10_{section_id}"):
                    # è·å–å‡€æµåŠ¨æœ€å¤§çš„å‰10ä¸ªåœ°å€
                    top_addresses = df.nlargest(10, 'net_tokens')['address'].tolist()
                    addresses_text = '\n'.join(top_addresses)
                    st.code(addresses_text, language=None)
                    st.success(f"âœ… å·²æ˜¾ç¤ºå‡€æµåŠ¨å‰10çš„åœ°å€")
            
            with col3:
                if st.button("ğŸ·ï¸ å¤åˆ¶æœ‰æ ‡ç­¾åœ°å€", key=f"copy_labeled_{section_id}"):
                    # è·å–æœ‰æ ‡ç­¾çš„åœ°å€
                    labeled_addresses = []
                    for _, row in df.iterrows():
                        addr = row['address']
                        if hasattr(self, 'analyzer') and self.analyzer and hasattr(self.analyzer, 'address_labels'):
                            if addr in self.analyzer.address_labels:
                                labeled_addresses.append(f"{addr} # {self.analyzer.address_labels[addr]}")
                    
                    if labeled_addresses:
                        addresses_text = '\n'.join(labeled_addresses)
                        st.code(addresses_text, language=None)
                        st.success(f"âœ… å·²æ˜¾ç¤º {len(labeled_addresses)} ä¸ªæœ‰æ ‡ç­¾åœ°å€")
                    else:
                        st.warning("æ²¡æœ‰æ‰¾åˆ°æœ‰æ ‡ç­¾çš„åœ°å€")
        
        elif section_id == "table_section":
            # æ•°æ®è¡¨åŒºåŸŸçš„ç‰¹æ®ŠæŒ‰é’®
            col1, col2, col3, col4 = st.columns([1, 1, 1, 1])
            
            with col1:
                if st.button("ğŸ“‹ å¤åˆ¶å½“å‰é¡µåœ°å€", key=f"copy_current_{section_id}", type="primary"):
                    all_addresses = df['address'].unique().tolist()
                    addresses_text = '\n'.join(all_addresses)
                    st.code(addresses_text, language=None)
                    st.success(f"âœ… å·²æ˜¾ç¤ºå½“å‰ç­›é€‰çš„ {len(all_addresses)} ä¸ªåœ°å€")
            
            with col2:
                if st.button("ğŸ’° å¤åˆ¶å¤§é¢åœ°å€", key=f"copy_big_{section_id}"):
                    # è·å–å¤§é¢äº¤æ˜“åœ°å€ï¼ˆé²¸é±¼ã€å¤§æˆ·ç­‰ï¼‰
                    big_types = ["é²¸é±¼ä¹°å…¥", "é²¸é±¼å–å‡º", "å¤§æˆ·ä¹°å…¥", "å¤§æˆ·å–å‡º", "å¤§ä¹°å®¶", "å¤§å–å®¶", "å¤§å‹åšå¸‚å•†"]
                    big_addresses = df[df['address_type'].isin(big_types)]['address'].unique().tolist()
                    
                    if big_addresses:
                        addresses_text = '\n'.join(big_addresses)
                        st.code(addresses_text, language=None)
                        st.success(f"âœ… å·²æ˜¾ç¤º {len(big_addresses)} ä¸ªå¤§é¢åœ°å€")
                    else:
                        st.warning("æ²¡æœ‰æ‰¾åˆ°å¤§é¢åœ°å€")
            
            with col3:
                if st.button("ğŸ“ˆ å¤åˆ¶å‡€æµå…¥åœ°å€", key=f"copy_inflow_{section_id}"):
                    # è·å–å‡€æµå…¥ä¸ºæ­£çš„åœ°å€
                    inflow_addresses = df[df['net_tokens'] > 0]['address'].tolist()
                    if inflow_addresses:
                        addresses_text = '\n'.join(inflow_addresses)
                        st.code(addresses_text, language=None)
                        st.success(f"âœ… å·²æ˜¾ç¤º {len(inflow_addresses)} ä¸ªå‡€æµå…¥åœ°å€")
                    else:
                        st.warning("æ²¡æœ‰æ‰¾åˆ°å‡€æµå…¥åœ°å€")
            
            with col4:
                if st.button("ğŸ“‰ å¤åˆ¶å‡€æµå‡ºåœ°å€", key=f"copy_outflow_{section_id}"):
                    # è·å–å‡€æµå‡ºä¸ºè´Ÿçš„åœ°å€
                    outflow_addresses = df[df['net_tokens'] < 0]['address'].tolist()
                    if outflow_addresses:
                        addresses_text = '\n'.join(outflow_addresses)
                        st.code(addresses_text, language=None)
                        st.success(f"âœ… å·²æ˜¾ç¤º {len(outflow_addresses)} ä¸ªå‡€æµå‡ºåœ°å€")
                    else:
                        st.warning("æ²¡æœ‰æ‰¾åˆ°å‡€æµå‡ºåœ°å€")
        
        else:
            # é»˜è®¤æŒ‰é’®
            col1, col2, col3 = st.columns([1, 1, 1])
            
            with col1:
                if st.button("ï¿½ å¤åˆ¶å…¨éƒ¨åœ°å€", key=f"copy_all_{section_id}", type="primary"):
                    all_addresses = df['address'].unique().tolist()
                    addresses_text = '\n'.join(all_addresses)
                    st.code(addresses_text, language=None)
                    st.success(f"âœ… å·²æ˜¾ç¤ºå…¨éƒ¨ {len(all_addresses)} ä¸ªåœ°å€")
            
            with col2:
                if st.button("ğŸ·ï¸ å¤åˆ¶æœ‰æ ‡ç­¾åœ°å€", key=f"copy_labeled_{section_id}"):
                    labeled_addresses = []
                    for _, row in df.iterrows():
                        addr = row['address']
                        if hasattr(self, 'analyzer') and self.analyzer and hasattr(self.analyzer, 'address_labels'):
                            if addr in self.analyzer.address_labels:
                                labeled_addresses.append(f"{addr} # {self.analyzer.address_labels[addr]}")
                    
                    if labeled_addresses:
                        addresses_text = '\n'.join(labeled_addresses)
                        st.code(addresses_text, language=None)
                        st.success(f"âœ… å·²æ˜¾ç¤º {len(labeled_addresses)} ä¸ªæœ‰æ ‡ç­¾åœ°å€")
                    else:
                        st.warning("æ²¡æœ‰æ‰¾åˆ°æœ‰æ ‡ç­¾çš„åœ°å€")
            
            with col3:
                if st.button("ğŸ’° å¤åˆ¶å¤§é¢åœ°å€", key=f"copy_big_{section_id}"):
                    big_types = ["é²¸é±¼ä¹°å…¥", "é²¸é±¼å–å‡º", "å¤§æˆ·ä¹°å…¥", "å¤§æˆ·å–å‡º", "å¤§ä¹°å®¶", "å¤§å–å®¶", "å¤§å‹åšå¸‚å•†"]
                    big_addresses = df[df['address_type'].isin(big_types)]['address'].unique().tolist()
                    
                    if big_addresses:
                        addresses_text = '\n'.join(big_addresses)
                        st.code(addresses_text, language=None)
                        st.success(f"âœ… å·²æ˜¾ç¤º {len(big_addresses)} ä¸ªå¤§é¢åœ°å€")
                    else:
                        st.warning("æ²¡æœ‰æ‰¾åˆ°å¤§é¢åœ°å€")

    def get_address_type_color(self, address_type):
        """æ ¹æ®åœ°å€ç±»å‹è¿”å›é¢œè‰²"""
        color_map = {
            "é²¸é±¼ä¹°å…¥": "#004d25",      # æ·±ç»¿è‰²
            "é²¸é±¼å–å‡º": "#8b0000",      # æ·±çº¢è‰²
            "å¤§å‹åšå¸‚å•†": "#ff6b35",     # æ©™çº¢è‰²
            "å¤§æˆ·ä¹°å…¥": "#28a745",      # ç»¿è‰²
            "å¤§æˆ·å–å‡º": "#dc3545",      # çº¢è‰²
            "å¤§ä¹°å®¶": "#28a745",        # ç»¿è‰²
            "å¤§å–å®¶": "#dc3545",        # çº¢è‰²
            "ä¸­ç­‰ä¹°å®¶": "#6f42c1",      # ç´«è‰²
            "ä¸­ç­‰å–å®¶": "#e83e8c",      # ç²‰çº¢è‰²
            "æ´»è·ƒä¹°å®¶": "#17a2b8",      # é’è‰²
            "æ´»è·ƒå–å®¶": "#fd7e14",      # æ©™è‰²
            "æ™®é€šä¹°å®¶": "#20c997",      # è–„è·ç»¿
            "æ™®é€šå–å®¶": "#ffc107",      # é»„è‰²
            "åšå¸‚å•†/å¥—åˆ©è€…": "#6c757d",  # ç°è‰²
            "æ— å‡€æµåŠ¨": "#adb5bd"       # æµ…ç°è‰²
        }
        return color_map.get(address_type, "#6c757d")
    
    def render_header(self):
        """æ¸²æŸ“é¡µé¢å¤´éƒ¨"""
        st.markdown("""
        <div class="main-header">
            ğŸ” Solscanä»£å¸æµåŠ¨åˆ†æå¹³å°
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem; color: #666;">
            å®æ—¶åˆ†æä»£å¸äº¤æ˜“æµåŠ¨ï¼Œè¯†åˆ«å‡€æµå…¥å’Œå‡€æµå‡ºæœ€å¤§çš„åœ°å€
        </div>
        """, unsafe_allow_html=True)
    
    def render_sidebar(self):
        """æ¸²æŸ“ä¾§è¾¹æ """
        st.sidebar.title("ğŸ“Š åˆ†ææ§åˆ¶é¢æ¿")
        
        # é€‰æ‹©æ“ä½œæ¨¡å¼
        st.sidebar.subheader("ğŸš€ æ“ä½œæ¨¡å¼")
        operation_mode = st.sidebar.radio(
            "é€‰æ‹©æ“ä½œ:",
            ["ğŸ“‚ ä½¿ç”¨ç°æœ‰æ•°æ®", "ğŸ”„ çˆ¬å–æ–°æ•°æ®"],
            help="é€‰æ‹©ä½¿ç”¨ç°æœ‰æ•°æ®æ–‡ä»¶è¿˜æ˜¯çˆ¬å–æ–°æ•°æ®"
        )
        
        selected_file = None
        crawl_config = None
        
        if operation_mode == "ğŸ“‚ ä½¿ç”¨ç°æœ‰æ•°æ®":
            # æ•°æ®æ–‡ä»¶é€‰æ‹©
            st.sidebar.subheader("ğŸ“‚ æ•°æ®æºé€‰æ‹©")
            data_files = self.load_available_data_files()
            
            if not data_files:
                st.sidebar.warning("æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼è¯·é€‰æ‹© 'ğŸ”„ çˆ¬å–æ–°æ•°æ®' æ¨¡å¼ã€‚")
                return None
            
            # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
            file_options = []
            for file_path in data_files:
                file_name = Path(file_path).name
                file_time = datetime.fromtimestamp(Path(file_path).stat().st_mtime)
                file_size = Path(file_path).stat().st_size / 1024  # KB
                display_name = f"{file_name} ({file_time.strftime('%m-%d %H:%M')}, {file_size:.1f}KB)"
                file_options.append((display_name, file_path))
            
            selected_option = st.sidebar.selectbox(
                "é€‰æ‹©æ•°æ®æ–‡ä»¶:",
                options=range(len(file_options)),
                format_func=lambda x: file_options[x][0],
                help="é€‰æ‹©è¦åˆ†æçš„æ•°æ®æ–‡ä»¶ï¼Œé»˜è®¤ä¸ºæœ€æ–°æ–‡ä»¶"
            )
            
            selected_file = file_options[selected_option][1] if file_options else None
            
        else:
            # çˆ¬å–é…ç½®
            st.sidebar.subheader("ğŸ•¸ï¸ çˆ¬å–é…ç½®")
            
            token_address = st.sidebar.text_input(
                "ä»£å¸åœ°å€:",
                value=st.session_state.crawl_config['token_address'],
                help="è¦çˆ¬å–çš„ä»£å¸åˆçº¦åœ°å€"
            )
            
            col1, col2 = st.sidebar.columns(2)
            with col1:
                max_pages = st.sidebar.number_input(
                    "æœ€å¤§é¡µæ•°:",
                    min_value=1,
                    max_value=200,
                    value=st.session_state.crawl_config['max_pages'],
                    help="é™åˆ¶çˆ¬å–çš„æœ€å¤§é¡µæ•°"
                )
            
            with col2:
                value_filter = st.sidebar.number_input(
                    "ä»·å€¼è¿‡æ»¤($):",
                    min_value=0.0,
                    max_value=1000.0,
                    value=float(st.session_state.crawl_config['value_filter']),
                    help="åªçˆ¬å–ä»·å€¼å¤§äºæ­¤å€¼çš„äº¤æ˜“"
                )
            
            # æ—¶é—´èŒƒå›´é…ç½®
            st.sidebar.subheader("â° æ—¶é—´èŒƒå›´ (å¯é€‰)")
            use_time_filter = st.sidebar.checkbox("å¯ç”¨æ—¶é—´è¿‡æ»¤", value=False)
            
            from_time = None
            to_time = None
            
            if use_time_filter:
                # ç®€åŒ–çš„æ—¶é—´è¾“å…¥
                st.sidebar.markdown("**å¼€å§‹æ—¶é—´**")
                from_datetime_str = st.sidebar.text_input(
                    "å¼€å§‹æ—¶é—´ (æ ¼å¼: YYYY-MM-DD HH:MM:SS)",
                    value="2025-08-30 09:00:00",
                    help="ä¾‹å¦‚: 2025-08-30 09:00:00"
                )
                
                st.sidebar.markdown("**ç»“æŸæ—¶é—´**")
                to_datetime_str = st.sidebar.text_input(
                    "ç»“æŸæ—¶é—´ (æ ¼å¼: YYYY-MM-DD HH:MM:SS)",
                    value="2025-08-30 10:00:00",
                    help="ä¾‹å¦‚: 2025-08-30 10:00:00"
                )
                
                # è§£ææ—¶é—´å­—ç¬¦ä¸²
                try:
                    from_datetime = datetime.strptime(from_datetime_str, "%Y-%m-%d %H:%M:%S")
                    to_datetime = datetime.strptime(to_datetime_str, "%Y-%m-%d %H:%M:%S")
                    
                    from_time = int(from_datetime.timestamp())
                    to_time = int(to_datetime.timestamp())
                    
                    # éªŒè¯æ—¶é—´èŒƒå›´
                    if to_time <= from_time:
                        st.sidebar.error("âš ï¸ ç»“æŸæ—¶é—´å¿…é¡»å¤§äºå¼€å§‹æ—¶é—´")
                        from_time = None
                        to_time = None
                    else:
                        # æ˜¾ç¤ºé€‰æ‹©çš„æ—¶é—´èŒƒå›´å’Œæ—¶é•¿
                        duration_hours = (to_time - from_time) / 3600
                        st.sidebar.success(f"âœ… æ—¶é—´èŒƒå›´: {duration_hours:.1f} å°æ—¶")
                        st.sidebar.info(f"ğŸ“… {from_datetime.strftime('%m-%d %H:%M')} è‡³ {to_datetime.strftime('%m-%d %H:%M')}")
                        
                except ValueError:
                    st.sidebar.error("âŒ æ—¶é—´æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD HH:MM:SS æ ¼å¼")
                    from_time = None
                    to_time = None
            
            crawl_config = {
                'token_address': token_address,
                'max_pages': max_pages,
                'value_filter': value_filter,
                'from_time': from_time,
                'to_time': to_time
            }
            
            # æ›´æ–°session state
            st.session_state.crawl_config = crawl_config
        
        # æ‰§è¡ŒæŒ‰é’®
        st.sidebar.subheader("ğŸ¯ æ‰§è¡Œæ“ä½œ")
        
        if operation_mode == "ğŸ“‚ ä½¿ç”¨ç°æœ‰æ•°æ®":
            analyze_button = st.sidebar.button(
                "ğŸš€ å¼€å§‹åˆ†æ",
                type="primary",
                width='stretch',
                help="åˆ†æé€‰å®šçš„æ•°æ®æ–‡ä»¶"
            )
            crawl_button = False
        else:
            crawl_button = st.sidebar.button(
                "ğŸ•¸ï¸ çˆ¬å–å¹¶åˆ†æ",
                type="primary",
                width='stretch',
                help="çˆ¬å–æ–°æ•°æ®å¹¶ç«‹å³å¼€å§‹åˆ†æ",
                disabled=st.session_state.crawl_in_progress
            )
            analyze_button = False
            
            if st.session_state.crawl_in_progress:
                st.sidebar.info("ğŸ”„ æ­£åœ¨çˆ¬å–æ•°æ®ï¼Œè¯·ç¨å€™...")
        
        return {
            'operation_mode': operation_mode,
            'selected_file': selected_file,
            'crawl_config': crawl_config,
            'analyze_button': analyze_button,
            'crawl_button': crawl_button
        }
    
    def load_and_analyze_data(self, file_path, min_value_threshold=0):
        """åŠ è½½å’Œåˆ†ææ•°æ®"""
        try:
            # æ˜¾ç¤ºè¿›åº¦
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # åˆå§‹åŒ–åˆ†æå™¨
            status_text.text("æ­£åœ¨åˆå§‹åŒ–åˆ†æå™¨...")
            progress_bar.progress(10)
            
            analyzer = TokenFlowAnalyzer()
            
            # åŠ è½½æ•°æ®
            status_text.text(f"æ­£åœ¨åŠ è½½æ•°æ®æ–‡ä»¶: {Path(file_path).name}...")
            progress_bar.progress(30)
            
            analyzer.load_data(file_path)
            
            # åº”ç”¨ä»·å€¼è¿‡æ»¤
            if min_value_threshold > 0:
                status_text.text(f"æ­£åœ¨åº”ç”¨ä»·å€¼è¿‡æ»¤ (>= ${min_value_threshold})...")
                progress_bar.progress(50)
                original_count = len(analyzer.df)
                analyzer.df = analyzer.df[analyzer.df['value'] >= min_value_threshold]
                filtered_count = len(analyzer.df)
                st.info(f"ä»·å€¼è¿‡æ»¤: {original_count} â†’ {filtered_count} æ¡è®°å½•")
            
            # è®¡ç®—å‡€æµåŠ¨
            status_text.text("æ­£åœ¨è®¡ç®—å‡€æµå…¥/æµå‡º...")
            progress_bar.progress(70)
            
            analyzer.calculate_net_flows()
            
            # å®Œæˆ
            status_text.text("åˆ†æå®Œæˆï¼")
            progress_bar.progress(100)
            
            time.sleep(0.5)
            progress_bar.empty()
            status_text.empty()
            
            return analyzer
            
        except Exception as e:
            st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
            return None
    
    def filter_data_by_types(self, df, selected_types):
        """æ ¹æ®åœ°å€ç±»å‹ç­›é€‰æ•°æ®"""
        if "å…¨éƒ¨" in selected_types:
            return df
        return df[df['address_type'].isin(selected_types)]
    
    def render_summary_metrics(self, analyzer):
        """æ¸²æŸ“æ±‡æ€»æŒ‡æ ‡"""
        st.subheader("ğŸ“Š æ€»ä½“æ¦‚è§ˆ")
        
        df = analyzer.net_flows_df
        
        # è®¡ç®—æŒ‡æ ‡ï¼ˆåŸºäºä»£å¸æ•°é‡å’Œç¾å…ƒä»·å€¼ï¼‰
        total_addresses = len(df)
        total_transactions = df['total_transactions'].sum()
        total_net_inflow_tokens = df[df['net_tokens'] > 0]['net_tokens'].sum()
        total_net_outflow_tokens = abs(df[df['net_tokens'] < 0]['net_tokens'].sum())
        total_net_inflow = df[df['net_value'] > 0]['net_value'].sum()
        total_net_outflow = abs(df[df['net_value'] < 0]['net_value'].sum())
        net_balance = total_net_inflow - total_net_outflow
        net_balance_tokens = total_net_inflow_tokens - total_net_outflow_tokens
        
        # æ˜¾ç¤ºæŒ‡æ ‡
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.metric(
                label="ğŸ“ æ€»åœ°å€æ•°",
                value=f"{total_addresses:,}",
                help="å‚ä¸äº¤æ˜“çš„å”¯ä¸€åœ°å€æ•°é‡"
            )
        
        with col2:
            st.metric(
                label="ğŸ“ æ€»äº¤æ˜“æ•°",
                value=f"{total_transactions:,}",
                help="æ‰€æœ‰åœ°å€çš„äº¤æ˜“æ€»æ•°"
            )
        
        with col3:
            st.metric(
                label="ğŸª™ æ€»å‡€æµå…¥(ä»£å¸)",
                value=self.format_tokens(total_net_inflow_tokens),
                help="æ‰€æœ‰åœ°å€å‡€æµå…¥çš„ä»£å¸æ•°é‡æ€»å’Œ"
            )
        
        with col4:
            st.metric(
                label="ğŸª™ æ€»å‡€æµå‡º(ä»£å¸)",
                value=self.format_tokens(total_net_outflow_tokens),
                delta_color="inverse",
                help="æ‰€æœ‰åœ°å€å‡€æµå‡ºçš„ä»£å¸æ•°é‡æ€»å’Œ"
            )
        
        with col5:
            st.metric(
                label="ï¿½ å‡€å¹³è¡¡(ç¾å…ƒ)",
                value=self.format_currency(net_balance),
                delta=f"{'+' if net_balance >= 0 else ''}{net_balance/1000:.1f}K" if abs(net_balance) > 1000 else None,
                delta_color="normal" if net_balance >= 0 else "inverse",
                help="æ€»å‡€æµå…¥ä¸æ€»å‡€æµå‡ºçš„å·®é¢ï¼ˆç¾å…ƒä»·å€¼ï¼‰"
            )
    
    def render_flow_charts(self, analyzer, top_n=20):
        """æ¸²æŸ“æµåŠ¨å›¾è¡¨"""
        st.subheader("ğŸ“ˆ å‡€æµåŠ¨å¯è§†åŒ–")
        
        df = analyzer.net_flows_df
        
        # åˆ›å»ºåŒåˆ—å¸ƒå±€
        col1, col2 = st.columns(2)
        
        with col1:
            # å‡€æµå…¥æ’è¡Œæ¦œ (ä»£å¸æ•°é‡)
            st.markdown("#### ğŸ† å‡€æµå…¥æ’è¡Œæ¦œ (ä»£å¸)")
            top_inflows = df.nlargest(top_n, 'net_tokens')
            
            if not top_inflows.empty:
                fig_inflow = px.bar(
                    top_inflows.head(10),
                    x='net_tokens',
                    y=top_inflows.head(10)['address'].apply(lambda x: self.format_address(x, 12, analyzer)),
                    orientation='h',
                    color='address_type',
                    color_discrete_map={t: self.get_address_type_color(t) for t in top_inflows['address_type'].unique()},
                    title=f"å‰10åå‡€æµå…¥åœ°å€ï¼ˆä»£å¸æ•°é‡ï¼‰",
                    labels={'net_tokens': 'å‡€æµå…¥ (ä»£å¸)', 'y': 'åœ°å€'}
                )
                fig_inflow.update_layout(height=400, yaxis={'categoryorder': 'total ascending'})
                st.plotly_chart(fig_inflow, width='stretch')
        
        with col2:
            # å‡€æµå‡ºæ’è¡Œæ¦œ (ä»£å¸æ•°é‡)
            st.markdown("#### ğŸ“‰ å‡€æµå‡ºæ’è¡Œæ¦œ (ä»£å¸)")
            top_outflows = df.nsmallest(top_n, 'net_tokens')
            
            if not top_outflows.empty:
                # è½¬æ¢ä¸ºæ­£å€¼ç”¨äºæ˜¾ç¤º
                top_outflows_display = top_outflows.head(10).copy()
                top_outflows_display['net_outflow'] = abs(top_outflows_display['net_tokens'])
                
                fig_outflow = px.bar(
                    top_outflows_display,
                    x='net_outflow',
                    y=top_outflows_display['address'].apply(lambda x: self.format_address(x, 12, analyzer)),
                    orientation='h',
                    color='address_type',
                    color_discrete_map={t: self.get_address_type_color(t) for t in top_outflows_display['address_type'].unique()},
                    title=f"å‰10åå‡€æµå‡ºåœ°å€ï¼ˆä»£å¸æ•°é‡ï¼‰",
                    labels={'net_outflow': 'å‡€æµå‡º (ä»£å¸)', 'y': 'åœ°å€'}
                )
                fig_outflow.update_layout(height=400, yaxis={'categoryorder': 'total ascending'})
                st.plotly_chart(fig_outflow, width='stretch')
        
        # åœ°å€ç±»å‹åˆ†å¸ƒé¥¼å›¾
        st.markdown("#### ğŸ¥§ åœ°å€ç±»å‹åˆ†å¸ƒ")
        type_counts = df['address_type'].value_counts()
        
        fig_pie = px.pie(
            values=type_counts.values,
            names=type_counts.index,
            title="åœ°å€ç±»å‹åˆ†å¸ƒ",
            color=type_counts.index,
            color_discrete_map={t: self.get_address_type_color(t) for t in type_counts.index}
        )
        fig_pie.update_layout(height=400)
        fig_pie.update_traces(
            hovertemplate="<b>%{label}</b><br>" +
                         "æ•°é‡: %{value}<br>" +
                         "å æ¯”: %{percent}<br>" +
                         "<extra></extra>"
        )
        st.plotly_chart(fig_pie, width='stretch')
        
        # æ·»åŠ æŒ‰ç±»å‹å¤åˆ¶åœ°å€åŠŸèƒ½
        with st.expander("ğŸ¥§ é¥¼å›¾åŒºåŸŸ - æŒ‰ç±»å‹å¤åˆ¶åœ°å€", expanded=False):
            st.markdown("*åŸºäºå½“å‰é¥¼å›¾æ˜¾ç¤ºçš„åœ°å€ç±»å‹åˆ†å¸ƒ*")
            self.render_address_copy_buttons(df, "chart_section")
    
    def render_all_addresses_table(self, analyzer):
        """æ¸²æŸ“æ‰€æœ‰åœ°å€çš„è¯¦ç»†è¡¨æ ¼ï¼ŒæŒ‰å‡€æµå…¥é‡æ’åº"""
        st.subheader("ğŸ“‹ æ‰€æœ‰åœ°å€è¯¦æƒ…è¡¨")
        
        df = analyzer.net_flows_df.copy()
        
        # æŒ‰å‡€æµå…¥é‡ä»å¤§åˆ°å°æ’åº
        df = df.sort_values('net_tokens', ascending=False)
        
        # æ·»åŠ æ’ååˆ—
        df['æ’å'] = range(1, len(df) + 1)
        
        # æ ¼å¼åŒ–æ˜¾ç¤ºæ•°æ®
        display_df = df.copy()
        display_df['åœ°å€/åç§°'] = display_df['address'].apply(lambda x: self.format_address(x, 25, analyzer))
        display_df['å®Œæ•´åœ°å€'] = display_df['address']  # ä¿ç•™å®Œæ•´åœ°å€ä¾¿äºå¤åˆ¶
        display_df['å‡€æµåŠ¨(ä»£å¸)'] = display_df['net_tokens'].apply(self.format_tokens)
        display_df['å‡€æµåŠ¨(ç¾å…ƒ)'] = display_df['net_value'].apply(self.format_currency)
        display_df['æµå…¥(ä»£å¸)'] = display_df['inflow_tokens'].apply(self.format_tokens)
        display_df['æµå‡º(ä»£å¸)'] = display_df['outflow_tokens'].apply(self.format_tokens)
        display_df['äº¤æ˜“æ•°'] = display_df['total_transactions']
        display_df['ç±»å‹'] = display_df['address_type']
        
        # æ·»åŠ ç­›é€‰å’Œæœç´¢åŠŸèƒ½
        col1, col2, col3 = st.columns([1, 1, 2])
        
        with col1:
            # ç±»å‹ç­›é€‰
            available_types = sorted(df['address_type'].unique().tolist())
            all_types = ["å…¨éƒ¨"] + available_types
            selected_type = st.selectbox("ğŸ·ï¸ ç­›é€‰ç±»å‹:", all_types, key="all_addresses_type_filter")
        
        with col2:
            # å‡€æµåŠ¨ç­›é€‰
            flow_options = ["å…¨éƒ¨", "ä»…å‡€æµå…¥", "ä»…å‡€æµå‡º", "ä»…å¤§é¢(>10Kä»£å¸)"]
            selected_flow = st.selectbox("ğŸ’° å‡€æµåŠ¨ç­›é€‰:", flow_options, key="all_addresses_flow_filter")
        
        with col3:
            # æœç´¢åŠŸèƒ½
            search_term = st.text_input("ğŸ” æœç´¢åœ°å€:", placeholder="è¾“å…¥åœ°å€æˆ–æ ‡ç­¾çš„éƒ¨åˆ†å­—ç¬¦", key="all_addresses_search")
        
        # åº”ç”¨ç­›é€‰
        filtered_df = display_df.copy()
        
        # ç±»å‹ç­›é€‰
        if selected_type != "å…¨éƒ¨":
            filtered_df = filtered_df[filtered_df['address_type'] == selected_type]
        
        # å‡€æµåŠ¨ç­›é€‰
        if selected_flow == "ä»…å‡€æµå…¥":
            filtered_df = filtered_df[df['net_tokens'] > 0]
        elif selected_flow == "ä»…å‡€æµå‡º":
            filtered_df = filtered_df[df['net_tokens'] < 0]
        elif selected_flow == "ä»…å¤§é¢(>10Kä»£å¸)":
            filtered_df = filtered_df[abs(df['net_tokens']) > 10000]
        
        # æœç´¢ç­›é€‰
        if search_term:
            mask = (
                filtered_df['address'].str.contains(search_term, case=False, na=False) |
                filtered_df['åœ°å€/åç§°'].str.contains(search_term, case=False, na=False)
            )
            filtered_df = filtered_df[mask]
        
        # æ˜¾ç¤ºç­›é€‰ç»“æœç»Ÿè®¡
        total_filtered = len(filtered_df)
        total_original = len(df)
        
        if selected_type != "å…¨éƒ¨" or selected_flow != "å…¨éƒ¨" or search_term:
            st.info(f"ğŸ“Š ç­›é€‰ç»“æœ: æ˜¾ç¤º {total_filtered} ä¸ªåœ°å€ (æ€»å…± {total_original} ä¸ª)")
        
        # åˆ†é¡µæ˜¾ç¤º
        items_per_page = 50
        total_pages = (total_filtered + items_per_page - 1) // items_per_page
        
        if total_pages > 1:
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                page = st.selectbox(
                    f"ğŸ“„ é€‰æ‹©é¡µé¢ (å…± {total_pages} é¡µ):",
                    range(1, total_pages + 1),
                    key="all_addresses_page"
                )
            
            start_idx = (page - 1) * items_per_page
            end_idx = min(start_idx + items_per_page, total_filtered)
            page_df = filtered_df.iloc[start_idx:end_idx].copy()
            
            st.caption(f"æ˜¾ç¤ºç¬¬ {start_idx + 1}-{end_idx} æ¡ï¼Œå…± {total_filtered} æ¡è®°å½•")
        else:
            page_df = filtered_df.copy()
        
        if not page_df.empty:
            # é‡æ–°è®¡ç®—æ’å
            page_df['æ˜¾ç¤ºæ’å'] = range(1, len(page_df) + 1) if selected_type != "å…¨éƒ¨" or selected_flow != "å…¨éƒ¨" or search_term else page_df['æ’å']
            
            # æ˜¾ç¤ºæ•°æ®è¡¨
            st.dataframe(
                page_df[['æ˜¾ç¤ºæ’å', 'åœ°å€/åç§°', 'å®Œæ•´åœ°å€', 'å‡€æµåŠ¨(ä»£å¸)', 'å‡€æµåŠ¨(ç¾å…ƒ)', 'æµå…¥(ä»£å¸)', 'æµå‡º(ä»£å¸)', 'äº¤æ˜“æ•°', 'ç±»å‹']],
                width='stretch',
                height=600,
                use_container_width=True
            )
            
            # ç»Ÿè®¡ä¿¡æ¯
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                net_inflow_count = len(page_df[df.loc[page_df.index, 'net_tokens'] > 0])
                st.metric("ğŸ“ˆ å‡€æµå…¥åœ°å€", f"{net_inflow_count} ä¸ª")
            
            with col2:
                net_outflow_count = len(page_df[df.loc[page_df.index, 'net_tokens'] < 0])
                st.metric("ğŸ“‰ å‡€æµå‡ºåœ°å€", f"{net_outflow_count} ä¸ª")
            
            with col3:
                total_net_tokens = df.loc[page_df.index, 'net_tokens'].sum()
                st.metric("ğŸª™ å½“å‰é¡µå‡€æµåŠ¨", self.format_tokens(total_net_tokens))
            
            with col4:
                total_net_value = df.loc[page_df.index, 'net_value'].sum()
                st.metric("ğŸ’° å½“å‰é¡µå‡€ä»·å€¼", self.format_currency(total_net_value))
            
            # ä¸‹è½½æŒ‰é’®
            csv = page_df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å½“å‰æ•°æ®ä¸ºCSV",
                data=csv,
                file_name=f"all_addresses_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
            
        else:
            st.info("æ²¡æœ‰ç¬¦åˆç­›é€‰æ¡ä»¶çš„åœ°å€æ•°æ®")
    
    def run(self):
        """è¿è¡Œåº”ç”¨ç¨‹åº"""
        self.initialize_session_state()
        
        # æ¸²æŸ“é¡µé¢
        self.render_header()
        
        # ä¾§è¾¹æ 
        sidebar_config = self.render_sidebar()
        
        if not sidebar_config:
            st.warning("è¯·é…ç½®çˆ¬å–å‚æ•°æˆ–é€‰æ‹©ç°æœ‰æ•°æ®æ–‡ä»¶ã€‚")
            st.stop()
        
        # å¤„ç†çˆ¬å–æ“ä½œ
        if sidebar_config['crawl_button']:
            st.session_state.crawl_in_progress = True
            st.session_state.analysis_complete = False
            
            st.info("ğŸš€ å¼€å§‹çˆ¬å–æ–°æ•°æ®...")
            
            # çˆ¬å–æ•°æ®
            crawl_result = self.crawl_new_data(sidebar_config['crawl_config'])
            
            if crawl_result:
                st.success(f"âœ… æ•°æ®çˆ¬å–æˆåŠŸï¼æ–‡ä»¶ä¿å­˜ä¸º: {Path(crawl_result).name}")
                
                # è‡ªåŠ¨å¼€å§‹åˆ†ææ–°çˆ¬å–çš„æ•°æ®
                st.info("ğŸ”„ æ­£åœ¨åˆ†ææ–°çˆ¬å–çš„æ•°æ®...")
                
                analyzer = self.load_and_analyze_data(
                    crawl_result,
                    0  # ä½¿ç”¨é»˜è®¤çš„æœ€å°ä»·å€¼è¿‡æ»¤
                )
                
                if analyzer:
                    st.session_state.analyzer = analyzer
                    st.session_state.analysis_complete = True
                    st.success("âœ… æ•°æ®åˆ†æå®Œæˆï¼")
                else:
                    st.error("âŒ æ•°æ®åˆ†æå¤±è´¥ï¼")
            else:
                st.error("âŒ æ•°æ®çˆ¬å–å¤±è´¥ï¼")
            
            st.session_state.crawl_in_progress = False
            st.rerun()
        
        # å¤„ç†åˆ†ææ“ä½œï¼ˆä½¿ç”¨ç°æœ‰æ•°æ®ï¼‰
        elif sidebar_config['analyze_button'] or st.session_state.analysis_complete:
            
            # åŠ è½½å’Œåˆ†ææ•°æ®
            if sidebar_config['analyze_button'] or not st.session_state.analysis_complete:
                with st.spinner("æ­£åœ¨åˆ†ææ•°æ®..."):
                    analyzer = self.load_and_analyze_data(
                        sidebar_config['selected_file'],
                        0  # ä½¿ç”¨é»˜è®¤çš„æœ€å°ä»·å€¼è¿‡æ»¤
                    )
                
                if analyzer:
                    st.session_state.analyzer = analyzer
                    st.session_state.analysis_complete = True
                    st.success("âœ… æ•°æ®åˆ†æå®Œæˆï¼")
                else:
                    st.error("âŒ æ•°æ®åˆ†æå¤±è´¥ï¼")
                    st.stop()
            
            analyzer = st.session_state.analyzer
            
            if analyzer and analyzer.net_flows_df is not None:
                # æ¸²æŸ“åˆ†æç»“æœ
                self.render_summary_metrics(analyzer)
                
                st.divider()
                
                self.render_flow_charts(analyzer, 20)  # ä½¿ç”¨é»˜è®¤çš„æ˜¾ç¤ºæ•°é‡
                
                st.divider()
                
                # æ·»åŠ æ‰€æœ‰åœ°å€è¡¨æ ¼
                self.render_all_addresses_table(analyzer)
                
                # é¡µè„šä¿¡æ¯
                st.markdown("---")
                st.markdown("""
                <div style="text-align: center; color: #666; font-size: 0.9rem;">
                    ğŸ” Solscanä»£å¸æµåŠ¨åˆ†æå¹³å° | 
                    ğŸ“Š æ•°æ®æ›´æ–°æ—¶é—´: {} | 
                    ğŸ› ï¸ ç”± LeviathanSunset å¼€å‘
                </div>
                """.format(datetime.now().strftime("%Y-%m-%d %H:%M:%S")), unsafe_allow_html=True)
            
        else:
            # åˆå§‹çŠ¶æ€é¡µé¢
            st.info("ğŸ‘† è¯·åœ¨å·¦ä¾§é¢æ¿é€‰æ‹©æ“ä½œæ¨¡å¼å¹¶ç‚¹å‡»ç›¸åº”æŒ‰é’®")
            
            # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
            with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜", expanded=True):
                st.markdown("""
                ### ğŸš€ æ–°åŠŸèƒ½ï¼šä¸€é”®çˆ¬å–å’Œåˆ†æ
                
                ç°åœ¨æ”¯æŒä¸¤ç§æ“ä½œæ¨¡å¼ï¼š
                
                #### ğŸ“‚ ä½¿ç”¨ç°æœ‰æ•°æ®
                1. **é€‰æ‹©æ–‡ä»¶**: ä»å·²æœ‰çš„æ•°æ®æ–‡ä»¶ä¸­é€‰æ‹©
                2. **è®¾ç½®å‚æ•°**: é…ç½®åˆ†æå‚æ•°ï¼ˆæ’è¡Œæ¦œæ•°é‡ã€ä»·å€¼è¿‡æ»¤ç­‰ï¼‰
                3. **å¼€å§‹åˆ†æ**: ç‚¹å‡» "ğŸš€ å¼€å§‹åˆ†æ" æŒ‰é’®
                
                #### ğŸ”„ çˆ¬å–æ–°æ•°æ®
                1. **é…ç½®çˆ¬å–**: è®¾ç½®ä»£å¸åœ°å€ã€é¡µæ•°é™åˆ¶ã€ä»·å€¼è¿‡æ»¤ç­‰
                2. **æ—¶é—´èŒƒå›´**: å¯é€‰æ‹©ç‰¹å®šæ—¶é—´æ®µçš„æ•°æ®
                3. **ä¸€é”®æ‰§è¡Œ**: ç‚¹å‡» "ğŸ•¸ï¸ çˆ¬å–å¹¶åˆ†æ" æŒ‰é’®è‡ªåŠ¨å®Œæˆçˆ¬å–å’Œåˆ†æ
                
                ### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½ï¼š
                - ğŸ“Š **å®æ—¶åˆ†æ**: è®¡ç®—æ¯ä¸ªåœ°å€çš„å‡€æµå…¥å’Œå‡€æµå‡º
                - ğŸ† **æ™ºèƒ½æ’è¡Œ**: æ˜¾ç¤ºå‡€æµå…¥/æµå‡ºæœ€å¤§çš„åœ°å€
                - ğŸ“ˆ **å¯è§†åŒ–**: äº¤äº’å¼å›¾è¡¨å±•ç¤ºæ•°æ®åˆ†å¸ƒ
                - ğŸ” **å¤šé‡ç­›é€‰**: æŒ‰åœ°å€ç±»å‹å’Œå…³é”®è¯ç­›é€‰æ•°æ®
                - ğŸ“¥ **æ•°æ®å¯¼å‡º**: æ”¯æŒCSVæ ¼å¼ä¸‹è½½
                - ğŸ•¸ï¸ **è‡ªåŠ¨çˆ¬å–**: æ— éœ€æ‰‹åŠ¨è¿è¡Œå‘½ä»¤è¡Œå·¥å…·
                
                ### ğŸ’¡ ä½¿ç”¨æŠ€å·§ï¼š
                - **æ—¶é—´è¿‡æ»¤**: å¯ç”¨æ—¶é—´èŒƒå›´å¯ä»¥åˆ†æç‰¹å®šæ—¶æ®µçš„äº¤æ˜“
                - **ä»·å€¼è¿‡æ»¤**: è®¾ç½®æœ€å°ä»·å€¼å¯ä»¥ä¸“æ³¨äºå¤§é¢äº¤æ˜“
                - **åœ°å€ç±»å‹**: ä½¿ç”¨ç±»å‹ç­›é€‰å¿«é€Ÿæ‰¾åˆ°é²¸é±¼æˆ–åšå¸‚å•†
                """)
            
            # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
            with st.expander("âš™ï¸ ç³»ç»ŸçŠ¶æ€"):
                data_files = self.load_available_data_files()
                st.write(f"ğŸ“ å·²æœ‰æ•°æ®æ–‡ä»¶: {len(data_files)} ä¸ª")
                
                if data_files:
                    latest_file = data_files[0]
                    file_time = datetime.fromtimestamp(Path(latest_file).stat().st_mtime)
                    st.write(f"ğŸ• æœ€æ–°æ•°æ®: {file_time.strftime('%Y-%m-%d %H:%M:%S')}")
                
                st.write(f"ğŸ”§ çˆ¬å–çŠ¶æ€: {'è¿›è¡Œä¸­' if st.session_state.crawl_in_progress else 'ç©ºé—²'}")
                st.write(f"ğŸ“Š åˆ†æçŠ¶æ€: {'å·²å®Œæˆ' if st.session_state.analysis_complete else 'æœªå¼€å§‹'}")

def main():
    """ä¸»å‡½æ•°"""
    app = StreamlitTokenFlowApp()
    app.run()

if __name__ == "__main__":
    main()
