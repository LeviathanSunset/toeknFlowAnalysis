#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Solscanä»£å¸æµåŠ¨åˆ†æ - Streamlitå¯è§†åŒ–åº”ç”¨
å±•ç¤ºå„ä¸ªåœ°å€çš„å‡€æµå…¥å’Œå‡€æµå‡ºåˆ†æ

ä½œè€…: LeviathanSunset
ç‰ˆæœ¬: 1.0.0
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
from pathlib import Path
from datetime import datetime
import time
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥è‡ªå®šä¹‰åˆ†ææ¨¡å—
try:
    from analysis import TokenFlowAnalyzer
    from solscanCrawler import SolscanAnalyzer
except ImportError as e:
    st.error(f"æ— æ³•å¯¼å…¥åˆ†ææ¨¡å—: {str(e)}")
    st.error("è¯·ç¡®ä¿ analysis.py å’Œ solscanCrawler.py æ–‡ä»¶å­˜åœ¨")
    st.stop()

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Solscanä»£å¸æµåŠ¨åˆ†æ",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        padding: 1rem;
        background: linear-gradient(90deg, #f0f8ff, #e6f3ff);
        border-radius: 10px;
        border: 2px solid #1f77b4;
    }
    
    .metric-container {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #1f77b4;
        margin: 1rem 0;
    }
    
    .net-inflow {
        color: #28a745;
        font-weight: bold;
    }
    
    .net-outflow {
        color: #dc3545;
        font-weight: bold;
    }
    
    .stDataFrame {
        border: 1px solid #dee2e6;
        border-radius: 5px;
    }
    
    .address-cell {
        font-family: 'Courier New', monospace;
        font-size: 0.9rem;
    }
</style>
""", unsafe_allow_html=True)

class StreamlitTokenFlowApp:
    """Streamlitä»£å¸æµåŠ¨åˆ†æåº”ç”¨"""
    
    def __init__(self):
        self.analyzer = None
        self.data_loaded = False
        self.net_flows_df = None
        
    def initialize_session_state(self):
        """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
        if 'analyzer' not in st.session_state:
            st.session_state.analyzer = None
        if 'data_loaded' not in st.session_state:
            st.session_state.data_loaded = False
        if 'crawl_in_progress' not in st.session_state:
            st.session_state.crawl_in_progress = False
        if 'crawl_config' not in st.session_state:
            st.session_state.crawl_config = {
                'token_address': '5zCETicUCJqJ5Z3wbfFPZqtSpHPYqnggs1wX7ZRpump',
                'max_pages': 50,
                'value_filter': 0.0
            }
    
    def load_available_data_files(self):
        """åŠ è½½å¯ç”¨çš„æ•°æ®æ–‡ä»¶"""
        storage_dir = Path("storage")
        if not storage_dir.exists():
            return []
        
        # æŸ¥æ‰¾JSONæ•°æ®æ–‡ä»¶
        json_files = list(storage_dir.glob("*.json"))
        json_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)  # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        
        return [str(f) for f in json_files]
    
    def format_address(self, address, max_length=20, analyzer=None):
        """æ ¼å¼åŒ–åœ°å€æ˜¾ç¤º"""
        if not address:
            return "N/A"
        
        # å°è¯•è·å–åœ°å€æ ‡ç­¾
        if analyzer and hasattr(analyzer, 'address_labels') and address in analyzer.address_labels:
            label = analyzer.address_labels[address]
            return f"ğŸ·ï¸ {label[:max_length]}..." if len(label) > max_length else f"ğŸ·ï¸ {label}"
        
        # æ˜¾ç¤ºåœ°å€çš„å‰åéƒ¨åˆ†
        if len(address) > max_length:
            return f"{address[:8]}...{address[-6:]}"
        else:
            return address
    
    def format_currency(self, value):
        """æ ¼å¼åŒ–è´§å¸æ˜¾ç¤º"""
        if pd.isna(value):
            return "$0.00"
        
        if abs(value) >= 1e6:
            return f"${value/1e6:.2f}M"
        elif abs(value) >= 1e3:
            return f"${value/1e3:.2f}K"
        else:
            return f"${value:.2f}"
    
    def format_tokens(self, value):
        """æ ¼å¼åŒ–ä»£å¸æ•°é‡æ˜¾ç¤º"""
        if pd.isna(value):
            return "0"
        
        if abs(value) >= 1e6:
            return f"{value/1e6:.2f}M"
        elif abs(value) >= 1e3:
            return f"{value/1e3:.2f}K"
        elif abs(value) >= 1:
            return f"{value:,.2f}"
        else:
            return f"{value:.6f}"
    
    def get_address_type_color(self, address_type):
        """æ ¹æ®åœ°å€ç±»å‹è¿”å›é¢œè‰²"""
        color_map = {
            "é²¸é±¼ä¹°å…¥": "#004d25",      # æ·±ç»¿è‰²
            "é²¸é±¼å–å‡º": "#8b0000",      # æ·±çº¢è‰²
            "å¤§å‹åšå¸‚å•†": "#ff6b35",     # æ©™çº¢è‰²
            "å¤§æˆ·ä¹°å…¥": "#28a745",      # ç»¿è‰²
            "å¤§æˆ·å–å‡º": "#dc3545",      # çº¢è‰²
            "å¤§ä¹°å®¶": "#28a745",        # ç»¿è‰²
            "å¤§å–å®¶": "#dc3545",        # çº¢è‰²
            "ä¸­ç­‰ä¹°å®¶": "#6f42c1",      # ç´«è‰²
            "ä¸­ç­‰å–å®¶": "#e83e8c",      # ç²‰çº¢è‰²
            "æ´»è·ƒä¹°å®¶": "#17a2b8",      # é’è‰²
            "æ´»è·ƒå–å®¶": "#fd7e14",      # æ©™è‰²
            "æ™®é€šä¹°å®¶": "#20c997",      # è–„è·ç»¿
            "æ™®é€šå–å®¶": "#ffc107",      # é»„è‰²
            "åšå¸‚å•†/å¥—åˆ©è€…": "#6c757d",  # ç°è‰²
            "æ— å‡€æµåŠ¨": "#adb5bd"       # æµ…ç°è‰²
        }
        return color_map.get(address_type, "#6c757d")
    
    def render_header(self):
        """æ¸²æŸ“é¡µé¢å¤´éƒ¨"""
        st.markdown("""
        <div class="main-header">
            ğŸ” Solscanä»£å¸æµåŠ¨åˆ†æå¹³å°
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem; color: #666;">
            å®æ—¶åˆ†æä»£å¸äº¤æ˜“æµåŠ¨ï¼Œè¯†åˆ«å‡€æµå…¥å’Œå‡€æµå‡ºæœ€å¤§çš„åœ°å€
        </div>
        """, unsafe_allow_html=True)
    
    def render_sidebar(self):
        """æ¸²æŸ“ä¾§è¾¹æ """
        st.sidebar.title("ğŸ“Š åˆ†ææ§åˆ¶é¢æ¿")
        
        # é€‰æ‹©æ“ä½œæ¨¡å¼
        st.sidebar.subheader("ğŸš€ æ“ä½œæ¨¡å¼")
        operation_mode = st.sidebar.radio(
            "é€‰æ‹©æ“ä½œ:",
            ["ğŸ“‚ ä½¿ç”¨ç°æœ‰æ•°æ®", "ğŸ”„ çˆ¬å–æ–°æ•°æ®"],
            help="é€‰æ‹©ä½¿ç”¨ç°æœ‰æ•°æ®æ–‡ä»¶è¿˜æ˜¯çˆ¬å–æ–°æ•°æ®"
        )
        
        selected_file = None
        crawl_config = None
        
        if operation_mode == "ğŸ“‚ ä½¿ç”¨ç°æœ‰æ•°æ®":
            # æ•°æ®æ–‡ä»¶é€‰æ‹©
            st.sidebar.subheader("ğŸ“‚ æ•°æ®æºé€‰æ‹©")
            data_files = self.load_available_data_files()
            
            if not data_files:
                st.sidebar.warning("æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼è¯·é€‰æ‹© 'ğŸ”„ çˆ¬å–æ–°æ•°æ®' æ¨¡å¼ã€‚")
                return None
            
            # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
            file_options = []
            for file_path in data_files:
                file_name = Path(file_path).name
                file_time = datetime.fromtimestamp(Path(file_path).stat().st_mtime)
                file_size = Path(file_path).stat().st_size / 1024  # KB
                display_name = f"{file_name} ({file_time.strftime('%m-%d %H:%M')}, {file_size:.1f}KB)"
                file_options.append((display_name, file_path))
            
            selected_option = st.sidebar.selectbox(
                "é€‰æ‹©æ•°æ®æ–‡ä»¶:",
                options=range(len(file_options)),
                format_func=lambda x: file_options[x][0],
                help="é€‰æ‹©è¦åˆ†æçš„æ•°æ®æ–‡ä»¶ï¼Œé»˜è®¤ä¸ºæœ€æ–°æ–‡ä»¶"
            )
            
            selected_file = file_options[selected_option][1] if file_options else None
            
        else:
            # çˆ¬å–é…ç½®
            st.sidebar.subheader("ğŸ•¸ï¸ çˆ¬å–é…ç½®")
            
            token_address = st.sidebar.text_input(
                "ä»£å¸åœ°å€:",
                value=st.session_state.crawl_config['token_address'],
                help="è¦çˆ¬å–çš„ä»£å¸åˆçº¦åœ°å€"
            )
            
            col1, col2 = st.sidebar.columns(2)
            with col1:
                max_pages = st.sidebar.number_input(
                    "æœ€å¤§é¡µæ•°:",
                    min_value=1,
                    max_value=200,
                    value=st.session_state.crawl_config['max_pages'],
                    help="é™åˆ¶çˆ¬å–çš„æœ€å¤§é¡µæ•°"
                )
            
            with col2:
                value_filter = st.sidebar.number_input(
                    "ä»·å€¼è¿‡æ»¤($):",
                    min_value=0.0,
                    max_value=1000.0,
                    value=float(st.session_state.crawl_config['value_filter']),
                    help="åªçˆ¬å–ä»·å€¼å¤§äºæ­¤å€¼çš„äº¤æ˜“"
                )
            
            # æ—¶é—´èŒƒå›´é…ç½®
            st.sidebar.subheader("â° æ—¶é—´èŒƒå›´ (å¯é€‰)")
            use_time_filter = st.sidebar.checkbox("å¯ç”¨æ—¶é—´è¿‡æ»¤", value=False)
            
            from_time = None
            to_time = None
            
            if use_time_filter:
                # ç®€åŒ–çš„æ—¶é—´è¾“å…¥
                st.sidebar.markdown("**å¼€å§‹æ—¶é—´**")
                from_datetime_str = st.sidebar.text_input(
                    "å¼€å§‹æ—¶é—´ (æ ¼å¼: YYYY-MM-DD HH:MM:SS)",
                    value="2025-08-30 09:00:00",
                    help="ä¾‹å¦‚: 2025-08-30 09:00:00"
                )
                
                st.sidebar.markdown("**ç»“æŸæ—¶é—´**")
                to_datetime_str = st.sidebar.text_input(
                    "ç»“æŸæ—¶é—´ (æ ¼å¼: YYYY-MM-DD HH:MM:SS)",
                    value="2025-08-30 10:00:00",
                    help="ä¾‹å¦‚: 2025-08-30 10:00:00"
                )
                
                # è§£ææ—¶é—´å­—ç¬¦ä¸²
                try:
                    from_datetime = datetime.strptime(from_datetime_str, "%Y-%m-%d %H:%M:%S")
                    to_datetime = datetime.strptime(to_datetime_str, "%Y-%m-%d %H:%M:%S")
                    
                    from_time = int(from_datetime.timestamp())
                    to_time = int(to_datetime.timestamp())
                    
                    # éªŒè¯æ—¶é—´èŒƒå›´
                    if to_time <= from_time:
                        st.sidebar.error("âš ï¸ ç»“æŸæ—¶é—´å¿…é¡»å¤§äºå¼€å§‹æ—¶é—´")
                        from_time = None
                        to_time = None
                    else:
                        # æ˜¾ç¤ºé€‰æ‹©çš„æ—¶é—´èŒƒå›´å’Œæ—¶é•¿
                        duration_hours = (to_time - from_time) / 3600
                        st.sidebar.success(f"âœ… æ—¶é—´èŒƒå›´: {duration_hours:.1f} å°æ—¶")
                        st.sidebar.info(f"ğŸ“… {from_datetime.strftime('%m-%d %H:%M')} è‡³ {to_datetime.strftime('%m-%d %H:%M')}")
                        
                except ValueError:
                    st.sidebar.error("âŒ æ—¶é—´æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD HH:MM:SS æ ¼å¼")
                    from_time = None
                    to_time = None
            
            crawl_config = {
                'token_address': token_address,
                'max_pages': max_pages,
                'value_filter': value_filter,
                'from_time': from_time,
                'to_time': to_time
            }
            
            # æ›´æ–°session state
            st.session_state.crawl_config = crawl_config
        
        # Cookiesç®¡ç†
        st.sidebar.subheader("ğŸ”§ Cookiesç®¡ç†")
        
        if operation_mode == "ğŸ”„ çˆ¬å–æ–°æ•°æ®" and token_address:
            if st.sidebar.button(
                "ğŸª æ›´æ–°Cookies",
                help=f"ä¸ºä»£å¸ {token_address} æ›´æ–°cookiesï¼Œç›´æ¥è®¿é—®å…¶ä»£å¸é¡µé¢"
            ):
                try:
                    with st.spinner("æ­£åœ¨æ›´æ–°cookies..."):
                        # åˆå§‹åŒ–çˆ¬è™«
                        crawler = SolscanAnalyzer()
                        success = crawler.update_cookies_for_token(token_address)
                        
                        if success:
                            st.sidebar.success("âœ… Cookiesæ›´æ–°æˆåŠŸï¼")
                        else:
                            st.sidebar.error("âŒ Cookiesæ›´æ–°å¤±è´¥")
                except Exception as e:
                    st.sidebar.error(f"âŒ æ›´æ–°å¤±è´¥: {str(e)}")
        else:
            st.sidebar.info("ğŸ’¡ è¯·å…ˆè¾“å…¥ä»£å¸åœ°å€ä»¥å¯ç”¨cookiesæ›´æ–°åŠŸèƒ½")
        
        # æ‰§è¡ŒæŒ‰é’®
        st.sidebar.subheader("ğŸ¯ æ‰§è¡Œæ“ä½œ")
        
        if operation_mode == "ğŸ“‚ ä½¿ç”¨ç°æœ‰æ•°æ®":
            analyze_button = st.sidebar.button(
                "ğŸš€ å¼€å§‹åˆ†æ",
                type="primary",
                width='stretch',
                help="åˆ†æé€‰å®šçš„æ•°æ®æ–‡ä»¶"
            )
            crawl_button = False
        else:
            crawl_button = st.sidebar.button(
                "ğŸ•¸ï¸ çˆ¬å–å¹¶åˆ†æ",
                type="primary",
                width='stretch',
                help="çˆ¬å–æ–°æ•°æ®å¹¶ç«‹å³å¼€å§‹åˆ†æ",
                disabled=st.session_state.crawl_in_progress
            )
            analyze_button = False
            
            if st.session_state.crawl_in_progress:
                st.sidebar.info("ğŸ”„ æ­£åœ¨çˆ¬å–æ•°æ®ï¼Œè¯·ç¨å€™...")
        
        return {
            'operation_mode': operation_mode,
            'selected_file': selected_file,
            'crawl_config': crawl_config,
            'analyze_button': analyze_button,
            'crawl_button': crawl_button
        }
    
    def render_flow_charts(self, analyzer, top_n=20):
        """æ¸²æŸ“æµåŠ¨å›¾è¡¨"""
        st.subheader("ğŸ“ˆ å‡€æµåŠ¨å¯è§†åŒ–")
        
        df = analyzer.net_flows_df
        
        # åˆ›å»ºåŒåˆ—å¸ƒå±€
        col1, col2 = st.columns(2)
        
        with col1:
            # å‡€æµå…¥æ’è¡Œæ¦œ (ä»£å¸æ•°é‡)
            st.markdown("#### ğŸ† å‡€æµå…¥æ’è¡Œæ¦œ (ä»£å¸)")
            top_inflows = df.nlargest(top_n, 'net_tokens')
            
            if not top_inflows.empty:
                fig_inflow = px.bar(
                    top_inflows.head(10),
                    x='net_tokens',
                    y=top_inflows.head(10)['address'].apply(lambda x: self.format_address(x, 12, analyzer)),
                    orientation='h',
                    color='address_type',
                    color_discrete_map={t: self.get_address_type_color(t) for t in top_inflows['address_type'].unique()},
                    title=f"å‰10åå‡€æµå…¥åœ°å€ï¼ˆä»£å¸æ•°é‡ï¼‰",
                    labels={'net_tokens': 'å‡€æµå…¥ (ä»£å¸)', 'y': 'åœ°å€'}
                )
                fig_inflow.update_layout(height=400, yaxis={'categoryorder': 'total ascending'})
                st.plotly_chart(fig_inflow, width='stretch')
        
        with col2:
            # å‡€æµå‡ºæ’è¡Œæ¦œ (ä»£å¸æ•°é‡)
            st.markdown("#### ğŸ“‰ å‡€æµå‡ºæ’è¡Œæ¦œ (ä»£å¸)")
            top_outflows = df.nsmallest(top_n, 'net_tokens')
            
            if not top_outflows.empty:
                # è½¬æ¢ä¸ºæ­£å€¼ç”¨äºæ˜¾ç¤º
                top_outflows_display = top_outflows.head(10).copy()
                top_outflows_display['net_outflow'] = abs(top_outflows_display['net_tokens'])
                
                fig_outflow = px.bar(
                    top_outflows_display,
                    x='net_outflow',
                    y=top_outflows_display['address'].apply(lambda x: self.format_address(x, 12, analyzer)),
                    orientation='h',
                    color='address_type',
                    color_discrete_map={t: self.get_address_type_color(t) for t in top_outflows_display['address_type'].unique()},
                    title=f"å‰10åå‡€æµå‡ºåœ°å€ï¼ˆä»£å¸æ•°é‡ï¼‰",
                    labels={'net_outflow': 'å‡€æµå‡º (ä»£å¸)', 'y': 'åœ°å€'}
                )
                fig_outflow.update_layout(height=400, yaxis={'categoryorder': 'total ascending'})
                st.plotly_chart(fig_outflow, width='stretch')
    
    def render_all_addresses_table(self, analyzer):
        """æ¸²æŸ“æ‰€æœ‰åœ°å€çš„è¯¦ç»†è¡¨æ ¼ï¼ŒæŒ‰å‡€æµå…¥é‡æ’åº"""
        st.subheader("ğŸ“‹ å®Œæ•´åœ°å€è¡¨ - æŒ‰å‡€æµé‡æ’åº")
        
        df = analyzer.net_flows_df.copy()
        
        # æŒ‰å‡€æµå…¥é‡ä»å¤§åˆ°å°æ’åºï¼ˆä»å¤§æµå…¥åˆ°å¤§æµå‡ºï¼‰
        df = df.sort_values('net_tokens', ascending=False)
        
        # æ·»åŠ æ’ååˆ—
        df['æ’å'] = range(1, len(df) + 1)
        
        # æ ¼å¼åŒ–æ˜¾ç¤ºæ•°æ®
        display_df = df.copy()
        display_df['åœ°å€/åç§°'] = display_df['address'].apply(lambda x: self.format_address(x, 25, analyzer))
        display_df['å‡€æµåŠ¨(ä»£å¸)'] = display_df['net_tokens'].apply(self.format_tokens)
        display_df['å‡€æµåŠ¨(ç¾å…ƒ)'] = display_df['net_value'].apply(self.format_currency)
        display_df['æµå…¥(ä»£å¸)'] = display_df['inflow_tokens'].apply(self.format_tokens)
        display_df['æµå‡º(ä»£å¸)'] = display_df['outflow_tokens'].apply(self.format_tokens)
        display_df['äº¤æ˜“æ•°'] = display_df['total_transactions']
        display_df['ç±»å‹'] = display_df['address_type']
        
        # æ ‡è®°è¢«æ’é™¤çš„åœ°å€
        display_df['æ˜¯å¦æ’é™¤'] = display_df['address'].apply(analyzer._is_excluded_address)
        
        # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
        display_columns = ['æ’å', 'åœ°å€/åç§°', 'å‡€æµåŠ¨(ä»£å¸)', 'å‡€æµåŠ¨(ç¾å…ƒ)', 'æµå…¥(ä»£å¸)', 'æµå‡º(ä»£å¸)', 'äº¤æ˜“æ•°', 'ç±»å‹']
        
        # ä¸ºè¢«æ’é™¤çš„åœ°å€åœ¨åœ°å€/åç§°åˆ—æ·»åŠ æ ‡è¯†
        display_df['åœ°å€/åç§°'] = display_df.apply(lambda row: 
            f"ğŸ”˜ {row['åœ°å€/åç§°']}" if row['æ˜¯å¦æ’é™¤'] else row['åœ°å€/åç§°'], axis=1)
        
        # ç›´æ¥æ˜¾ç¤ºæ•°æ®æ¡†ï¼Œä¸ä½¿ç”¨å¤æ‚çš„æ ·å¼
        final_df = display_df[display_columns]
        
        # æ˜¾ç¤ºå®Œæ•´æ•°æ®è¡¨
        st.dataframe(
            final_df,
            width='stretch',
            height=800,
            use_container_width=True
        )
        
        # æ·»åŠ è¯´æ˜
        st.markdown("""
        **ğŸ” è¡¨æ ¼è¯´æ˜ï¼š**
        - ğŸŸ¢ **æ­£å¸¸æ˜¾ç¤º**ï¼šçœŸå®äº¤æ˜“åœ°å€
        - ğŸ”˜ **å¸¦åœ†åœˆæ ‡è¯†**ï¼šè¢«æ’é™¤çš„åœ°å€ï¼ˆèšåˆå™¨ã€æ± å­ã€äº¤æ˜“æ‰€ç­‰ï¼‰
        - æ’åºæ–¹å¼ï¼šæŒ‰å‡€æµé‡ä»å¤§æµå…¥åˆ°å¤§æµå‡ºæ’åº
        """)
        
        # ç§»é™¤äº†åº•éƒ¨ç»Ÿè®¡ä¿¡æ¯ï¼Œç»Ÿè®¡æ•°æ®å·²ç§»è‡³é¡¶éƒ¨
        
        # ä¸‹è½½æŒ‰é’®
        csv = final_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å®Œæ•´æ•°æ®ä¸ºCSV",
            data=csv,
            file_name=f"complete_addresses_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    def load_and_analyze_data(self, file_path, min_value_threshold=0):
        """åŠ è½½å’Œåˆ†ææ•°æ®"""
        try:
            # æ˜¾ç¤ºè¿›åº¦
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # åˆå§‹åŒ–åˆ†æå™¨
            status_text.text("ğŸ”„ åˆå§‹åŒ–åˆ†æå™¨...")
            progress_bar.progress(10)
            
            analyzer = TokenFlowAnalyzer()
            
            # åŠ è½½æ•°æ®
            status_text.text("ğŸ“‚ åŠ è½½æ•°æ®æ–‡ä»¶...")
            progress_bar.progress(30)
            
            success = analyzer.load_data(file_path)
            if not success:
                progress_bar.empty()
                status_text.empty()
                st.error("âŒ æ•°æ®åŠ è½½å¤±è´¥")
                st.error("è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®")
                return None
            
            # åˆ†æå‡€æµåŠ¨
            status_text.text("ğŸ” åˆ†æå‡€æµåŠ¨...")
            progress_bar.progress(60)
            
            analyzer.calculate_net_flows()
            
            # åº”ç”¨ç­›é€‰
            if min_value_threshold > 0:
                status_text.text("ğŸ¯ åº”ç”¨ä»·å€¼ç­›é€‰...")
                progress_bar.progress(80)
                
                analyzer.filter_by_value(min_value_threshold)
            
            # å®Œæˆ
            status_text.text("âœ… åˆ†æå®Œæˆï¼")
            progress_bar.progress(100)
            
            time.sleep(0.5)  # è®©ç”¨æˆ·çœ‹åˆ°å®ŒæˆçŠ¶æ€
            progress_bar.empty()
            status_text.empty()
            
            return analyzer
            
        except Exception as e:
            progress_bar.empty()
            status_text.empty()
            st.error(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            st.error("è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶æ ¼å¼æˆ–è”ç³»æŠ€æœ¯æ”¯æŒ")
            return None
    
    def crawl_and_analyze_data(self, config):
        """çˆ¬å–å¹¶åˆ†ææ•°æ®"""
        try:
            st.session_state.crawl_in_progress = True
            
            # æ˜¾ç¤ºè¿›åº¦
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # åˆå§‹åŒ–çˆ¬è™«
            status_text.text("ğŸ”„ åˆå§‹åŒ–çˆ¬è™«...")
            progress_bar.progress(5)
            
            crawler = SolscanAnalyzer()
            
            # å¼€å§‹çˆ¬å–
            status_text.text("ğŸ•¸ï¸ å¼€å§‹çˆ¬å–æ•°æ®...")
            progress_bar.progress(10)
            
            all_data = []
            page = 1
            max_pages = config['max_pages']
            
            while page <= max_pages:
                status_text.text(f"ğŸ“¡ çˆ¬å–ç¬¬ {page}/{max_pages} é¡µ...")
                progress = 10 + int((page / max_pages) * 60)
                progress_bar.progress(progress)
                
                data = crawler.get_token_transfers(
                    address=config['token_address'],
                    page=page,
                    from_time=config.get('from_time'),
                    to_time=config.get('to_time'),
                    value_filter=config.get('value_filter')
                )
                
                if not data or not data.get('data'):
                    status_text.text(f"âš ï¸ ç¬¬ {page} é¡µæ— æ•°æ®ï¼Œåœæ­¢çˆ¬å–")
                    break
                
                all_data.extend(data['data'])
                page += 1
                
                time.sleep(0.5)  # é˜²æ­¢è¯·æ±‚è¿‡å¿«
            
            if not all_data:
                st.error("âŒ æœªçˆ¬å–åˆ°ä»»ä½•æ•°æ®")
                return None
            
            # ä¿å­˜æ•°æ®
            status_text.text("ğŸ’¾ ä¿å­˜çˆ¬å–æ•°æ®...")
            progress_bar.progress(75)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            file_path = f"storage/solscan_data_{timestamp}.json"
            
            os.makedirs("storage", exist_ok=True)
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(all_data, f, ensure_ascii=False, indent=2)
            
            # åˆ†ææ•°æ®
            status_text.text("ğŸ” åˆ†æçˆ¬å–æ•°æ®...")
            progress_bar.progress(85)
            
            analyzer = TokenFlowAnalyzer()
            success = analyzer.load_data(file_path)
            
            if not success:
                st.error("âŒ æ•°æ®åˆ†æå¤±è´¥")
                return None
            
            analyzer.calculate_net_flows()
            
            # å®Œæˆ
            status_text.text("âœ… çˆ¬å–å’Œåˆ†æå®Œæˆï¼")
            progress_bar.progress(100)
            
            time.sleep(0.5)
            progress_bar.empty()
            status_text.empty()
            
            st.success(f"ğŸ‰ æˆåŠŸçˆ¬å– {len(all_data)} æ¡äº¤æ˜“è®°å½•ï¼")
            
            return analyzer
            
        except Exception as e:
            st.error(f"âŒ çˆ¬å–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            return None
        finally:
            st.session_state.crawl_in_progress = False
    
    def render_summary_metrics(self, analyzer):
        """æ¸²æŸ“æ€»ç»“æŒ‡æ ‡"""
        st.subheader("ğŸ“Š æ€»ä½“æ¦‚è§ˆ")
        
        df = analyzer.net_flows_df
        
        # è®¡ç®—å…³é”®æŒ‡æ ‡
        total_addresses = len(df)
        net_inflow_addresses = len(df[df['net_tokens'] > 0])
        net_outflow_addresses = len(df[df['net_tokens'] < 0])
        total_net_tokens = df['net_tokens'].sum()
        total_net_value = df['net_value'].sum()
        
        # è¿‡æ»¤å‡ºçœŸå®äº¤æ˜“åœ°å€ï¼ˆæ’é™¤èšåˆå™¨ã€æ± å­ã€äº¤æ˜“æ‰€ï¼‰
        real_traders_df = df[df['address'].apply(analyzer._is_real_trader_address)]
        
        # è®¡ç®—çœŸå®äº¤æ˜“åœ°å€çš„ç»Ÿè®¡æ•°æ®
        real_inflow_df = real_traders_df[real_traders_df['net_tokens'] > 0]
        real_outflow_df = real_traders_df[real_traders_df['net_tokens'] < 0]
        
        real_total_inflow_tokens = real_inflow_df['net_tokens'].sum() if len(real_inflow_df) > 0 else 0
        real_total_outflow_tokens = abs(real_outflow_df['net_tokens'].sum()) if len(real_outflow_df) > 0 else 0
        
        # è®¡ç®—å¹³å‡æ¯ä¸ªçœŸå®å‡€æµå…¥åœ°å€çš„æµå…¥é‡
        avg_inflow_per_address = real_total_inflow_tokens / len(real_inflow_df) if len(real_inflow_df) > 0 else 0
        # è®¡ç®—å¹³å‡æ¯ä¸ªçœŸå®å‡€æµå‡ºåœ°å€çš„æµå‡ºé‡
        avg_outflow_per_address = real_total_outflow_tokens / len(real_outflow_df) if len(real_outflow_df) > 0 else 0
        
        # è·å–æœ€å¤§å‡€æµå…¥å’Œå‡€æµå‡º
        max_inflow = df['net_tokens'].max()
        max_outflow = df['net_tokens'].min()
        
        # æ˜¾ç¤ºæŒ‡æ ‡
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                label="ğŸ  æ€»åœ°å€æ•°",
                value=f"{total_addresses:,}",
                delta=f"çœŸå®äº¤æ˜“: {len(real_traders_df):,}",
                help=f"å‚ä¸äº¤æ˜“çš„å”¯ä¸€åœ°å€æ€»æ•° (åŒ…å« {total_addresses - len(real_traders_df)} ä¸ªèšåˆå™¨/æ± å­/äº¤æ˜“æ‰€)"
            )
        
        with col2:
            st.metric(
                label="ğŸ“ˆ å‡€æµå…¥åœ°å€",
                value=f"{net_inflow_addresses:,}",
                delta=f"å¹³å‡: {self.format_tokens(avg_inflow_per_address)}",
                help=f"å‡€æµå…¥ä¸ºæ­£çš„åœ°å€æ•°é‡ (å æ¯”: {net_inflow_addresses/total_addresses*100:.1f}%) \nå¹³å‡å€¼åŸºäº {len(real_inflow_df)} ä¸ªçœŸå®äº¤æ˜“åœ°å€è®¡ç®—"
            )
        
        with col3:
            st.metric(
                label="ï¿½ å‡€æµå‡ºåœ°å€",
                value=f"{net_outflow_addresses:,}",
                delta=f"å¹³å‡: {self.format_tokens(avg_outflow_per_address)}",
                delta_color="inverse",
                help=f"å‡€æµå‡ºä¸ºè´Ÿçš„åœ°å€æ•°é‡ (å æ¯”: {net_outflow_addresses/total_addresses*100:.1f}%)"
            )
    
    def run(self):
        """è¿è¡Œåº”ç”¨ç¨‹åº"""
        self.initialize_session_state()
        
        # æ¸²æŸ“é¡µé¢
        self.render_header()
        
        # ä¾§è¾¹æ 
        sidebar_config = self.render_sidebar()
        
        if not sidebar_config:
            st.warning("è¯·é…ç½®çˆ¬å–å‚æ•°æˆ–é€‰æ‹©ç°æœ‰æ•°æ®æ–‡ä»¶ã€‚")
            st.stop()
        
        # å¤„ç†ç”¨æˆ·æ“ä½œ
        if sidebar_config['analyze_button']:
            # åˆ†æç°æœ‰æ•°æ®
            if sidebar_config['selected_file']:
                analyzer = self.load_and_analyze_data(sidebar_config['selected_file'])
                if analyzer:
                    st.session_state.analyzer = analyzer
                    st.session_state.data_loaded = True
                    st.rerun()
        
        elif sidebar_config['crawl_button']:
            # çˆ¬å–æ–°æ•°æ®
            if sidebar_config['crawl_config']:
                analyzer = self.crawl_and_analyze_data(sidebar_config['crawl_config'])
                if analyzer:
                    st.session_state.analyzer = analyzer
                    st.session_state.data_loaded = True
                    st.rerun()
        
        # æ˜¾ç¤ºåˆ†æç»“æœ
        if st.session_state.data_loaded and st.session_state.analyzer:
            analyzer = st.session_state.analyzer
            
            # æ˜¾ç¤ºæ€»ç»“æŒ‡æ ‡
            self.render_summary_metrics(analyzer)
            
            # æ˜¾ç¤ºå›¾è¡¨
            self.render_flow_charts(analyzer, 20)  # ä½¿ç”¨é»˜è®¤çš„æ˜¾ç¤ºæ•°é‡
            
            # æ˜¾ç¤ºå®Œæ•´åœ°å€è¡¨
            self.render_all_addresses_table(analyzer)
            
        else:
            # æ¬¢è¿é¡µé¢
            st.markdown("""
            ## ğŸ” ä»£å¸æµåŠ¨åˆ†æå·¥å…·
            
            ### åŠŸèƒ½ç‰¹ç‚¹ï¼š
            - ğŸ•¸ï¸ **å®æ—¶æ•°æ®çˆ¬å–**: ä»Solscan APIè·å–æœ€æ–°äº¤æ˜“æ•°æ®
            - ğŸ“Š **å‡€æµåŠ¨åˆ†æ**: è‡ªåŠ¨è®¡ç®—æ¯ä¸ªåœ°å€çš„å‡€æµå…¥/å‡€æµå‡º
            - ğŸ·ï¸ **åœ°å€æ ‡ç­¾è¯†åˆ«**: è‡ªåŠ¨è¯†åˆ«åœ°å€ç±»å‹ï¼ˆé²¸é±¼ã€åšå¸‚å•†ç­‰ï¼‰
            - ğŸ“ˆ **å¯è§†åŒ–å›¾è¡¨**: ç›´è§‚å±•ç¤ºæµåŠ¨è¶‹åŠ¿å’Œæ’è¡Œæ¦œ
            - ğŸ“‹ **å®Œæ•´æ•°æ®è¡¨**: è¯¦ç»†çš„åœ°å€æµåŠ¨ä¿¡æ¯
            - ğŸ’¾ **æ•°æ®å¯¼å‡º**: æ”¯æŒCSVæ ¼å¼ä¸‹è½½
            
            ### ä½¿ç”¨æ–¹æ³•ï¼š
            1. åœ¨å·¦ä¾§é€‰æ‹©æ“ä½œæ¨¡å¼ï¼ˆä½¿ç”¨ç°æœ‰æ•°æ®æˆ–çˆ¬å–æ–°æ•°æ®ï¼‰
            2. é…ç½®ç›¸åº”çš„å‚æ•°
            3. ç‚¹å‡»æ‰§è¡ŒæŒ‰é’®å¼€å§‹åˆ†æ
            4. æŸ¥çœ‹åˆ†æç»“æœå’Œå¯è§†åŒ–å›¾è¡¨
            
            ### å¼€å§‹ä½¿ç”¨ï¼š
            ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é¢æ¿é€‰æ‹©æ“ä½œæ¨¡å¼å¹¶é…ç½®å‚æ•°
            """)

def main():
    """ä¸»å‡½æ•°"""
    app = StreamlitTokenFlowApp()
    app.run()

if __name__ == "__main__":
    main()
