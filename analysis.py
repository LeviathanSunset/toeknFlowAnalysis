#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åœ°å€å‡€æµå…¥å‡€æµå‡ºåˆ†æè„šæœ¬
åˆ†æä»£å¸è½¬è´¦æ•°æ®ï¼Œè®¡ç®—æ‰€æœ‰åœ°å€çš„å‡€æµå…¥å’Œå‡€æµå‡ºæ’è¡Œæ¦œ
"""

import json
import argparse
import os
from collections import defaultdict
from datetime import datetime
from typing import Dict, List, Tuple


class TokenFlowAnalyzer:
    """ä»£å¸æµåŠ¨åˆ†æå™¨"""
    
    def __init__(self, json_file_path: str):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            json_file_path: JSONæ•°æ®æ–‡ä»¶è·¯å¾„
        """
        self.json_file_path = json_file_path
        self.address_flows = defaultdict(lambda: {'inflow': 0, 'outflow': 0, 'net_flow': 0})
        self.total_transactions = 0
        self.total_volume = 0
        self.token_info = {}
        
    def load_data(self) -> bool:
        """
        åŠ è½½JSONæ•°æ®æ–‡ä»¶
        
        Returns:
            bool: åŠ è½½æ˜¯å¦æˆåŠŸ
        """
        try:
            print(f"ğŸ“‚ æ­£åœ¨åŠ è½½æ•°æ®æ–‡ä»¶: {self.json_file_path}")
            
            if not os.path.exists(self.json_file_path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {self.json_file_path}")
                return False
                
            with open(self.json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            if not data.get('success', False):
                print("âŒ æ•°æ®æ–‡ä»¶æ˜¾ç¤ºçˆ¬å–å¤±è´¥")
                return False
                
            self.raw_data = data
            self.transactions = data.get('data', [])
            self.total_transactions = len(self.transactions)
            
            print(f"âœ… æˆåŠŸåŠ è½½ {self.total_transactions} æ¡äº¤æ˜“è®°å½•")
            print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡: æ€»é¡µæ•° {data.get('total_pages', 0)}, æ€»è®°å½•æ•° {data.get('total_records', 0)}")
            
            if self.transactions:
                # è·å–ä»£å¸ä¿¡æ¯
                first_tx = self.transactions[0]
                self.token_info = {
                    'address': first_tx.get('token_address', ''),
                    'decimals': first_tx.get('token_decimals', 6)
                }
                print(f"ğŸª™ ä»£å¸åœ°å€: {self.token_info['address']}")
                print(f"ğŸ”¢ ä»£å¸ç²¾åº¦: {self.token_info['decimals']}")
            
            return True
            
        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {self.json_file_path}")
            return False
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æé”™è¯¯: {e}")
            return False
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def analyze_flows(self):
        """åˆ†æåœ°å€æµå…¥æµå‡º"""
        print("\nğŸ” å¼€å§‹åˆ†æåœ°å€æµåŠ¨...")
        
        for tx in self.transactions:
            from_addr = tx.get('from_address', '')
            to_addr = tx.get('to_address', '')
            amount = float(tx.get('amount', 0))
            token_decimals = tx.get('token_decimals', 6)
            
            if not from_addr or not to_addr or amount <= 0:
                continue
            
            # å°†åŸå§‹æ•°é‡è½¬æ¢ä¸ºå®é™…ä»£å¸æ•°é‡ï¼ˆè€ƒè™‘ç²¾åº¦ï¼‰
            token_amount = amount / (10 ** token_decimals)
                
            # è®¡ç®—æµå‡ºï¼ˆfrom_addressï¼‰
            self.address_flows[from_addr]['outflow'] += token_amount
            self.address_flows[from_addr]['net_flow'] -= token_amount
            
            # è®¡ç®—æµå…¥ï¼ˆto_addressï¼‰
            self.address_flows[to_addr]['inflow'] += token_amount
            self.address_flows[to_addr]['net_flow'] += token_amount
            
            self.total_volume += token_amount
        
        print(f"âœ… åˆ†æå®Œæˆï¼Œå…±å¤„ç† {len(self.address_flows)} ä¸ªåœ°å€")
        print(f"ğŸª™ æ€»äº¤æ˜“æ•°é‡: {self.total_volume:,.2f} ä»£å¸")
    
    def get_top_addresses(self, sort_by: str = 'net_flow', limit: int = 50) -> List[Tuple[str, Dict]]:
        """
        è·å–æ’è¡Œæ¦œ
        
        Args:
            sort_by: æ’åºå­—æ®µ ('net_flow', 'inflow', 'outflow')
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            List[Tuple[str, Dict]]: æ’åºåçš„åœ°å€åˆ—è¡¨
        """
        if sort_by not in ['net_flow', 'inflow', 'outflow']:
            raise ValueError("sort_by å¿…é¡»æ˜¯ 'net_flow', 'inflow', æˆ– 'outflow'")
        
        # æŒ‰æŒ‡å®šå­—æ®µæ’åº
        sorted_addresses = sorted(
            self.address_flows.items(),
            key=lambda x: x[1][sort_by],
            reverse=True
        )
        
        return sorted_addresses[:limit]
    
    def get_net_outflow_addresses(self, limit: int = 50) -> List[Tuple[str, Dict]]:
        """
        è·å–å‡€æµå‡ºæ’è¡Œæ¦œï¼ˆå‡€æµå…¥ä¸ºè´Ÿå€¼çš„åœ°å€ï¼ŒæŒ‰ç»å¯¹å€¼ä»å¤§åˆ°å°æ’åºï¼‰
        
        Args:
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            List[Tuple[str, Dict]]: å‡€æµå‡ºåœ°å€åˆ—è¡¨
        """
        # åªé€‰æ‹©å‡€æµå‡ºçš„åœ°å€ï¼ˆnet_flow < 0ï¼‰ï¼ŒæŒ‰net_flowä»å°åˆ°å¤§æ’åº
        net_outflow_addresses = [
            (addr, flows) for addr, flows in self.address_flows.items()
            if flows['net_flow'] < 0
        ]
        
        # æŒ‰å‡€æµå…¥å€¼ä»å°åˆ°å¤§æ’åºï¼ˆè´Ÿæ•°è¶Šå°è¡¨ç¤ºå‡€æµå‡ºè¶Šå¤šï¼‰
        sorted_addresses = sorted(
            net_outflow_addresses,
            key=lambda x: x[1]['net_flow'],
            reverse=False  # ä»å°åˆ°å¤§
        )
        
        return sorted_addresses[:limit]
    
    def print_ranking(self, ranking_type: str = 'net_flow', limit: int = 20):
        """
        æ‰“å°æ’è¡Œæ¦œ
        
        Args:
            ranking_type: æ’è¡Œç±»å‹ ('net_flow', 'inflow', 'outflow')
            limit: æ˜¾ç¤ºæ•°é‡é™åˆ¶
        """
        title_map = {
            'net_flow': 'ğŸ“ˆ å‡€æµå…¥æ’è¡Œæ¦œï¼ˆæ­£å€¼ä¸ºå‡€æµå…¥ï¼Œè´Ÿå€¼ä¸ºå‡€æµå‡ºï¼‰',
            'net_outflow': 'ğŸ“‰ å‡€æµå‡ºæ’è¡Œæ¦œï¼ˆæŒ‰æµå‡ºé‡‘é¢æ’åºï¼‰',
            'inflow': 'ğŸ’° æµå…¥æ’è¡Œæ¦œ',
            'outflow': 'ğŸ’¸ æµå‡ºæ’è¡Œæ¦œ'
        }
        
        print(f"\n{title_map.get(ranking_type, 'æ’è¡Œæ¦œ')}")
        print("=" * 80)
        print(f"{'æ’å':<5} {'åœ°å€':<45} {'ä»£å¸æ•°é‡':<20}")
        print("-" * 80)
        
        if ranking_type == 'net_outflow':
            top_addresses = self.get_net_outflow_addresses(limit)
        else:
            top_addresses = self.get_top_addresses(ranking_type, limit)
        
        for rank, (address, flows) in enumerate(top_addresses, 1):
            if ranking_type == 'net_outflow':
                amount = flows['net_flow']  # è¿™é‡Œæ˜¯è´Ÿå€¼
                amount_str = f"-{abs(amount):,.2f}"
            else:
                amount = flows[ranking_type]
                
                # æ ¼å¼åŒ–é‡‘é¢æ˜¾ç¤º
                if ranking_type == 'net_flow':
                    if amount >= 0:
                        amount_str = f"+{amount:,.2f}"
                    else:
                        amount_str = f"-{abs(amount):,.2f}"
                else:
                    amount_str = f"{amount:,.2f}"
            
            print(f"{rank:<5} {address:<45} {amount_str:<20}")
    
    def save_analysis_report(self, output_file: str = None):
        """
        ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°æ–‡ä»¶
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        """
        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"storage/analysis_report_{timestamp}.json"
            
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        # å‡†å¤‡æŠ¥å‘Šæ•°æ®
        report = {
            "analysis_info": {
                "input_file": self.json_file_path,
                "analysis_time": datetime.now().isoformat(),
                "total_addresses": len(self.address_flows),
                "total_transactions": self.total_transactions,
                "total_volume": self.total_volume,
                "token_info": self.token_info
            },
            "rankings": {
                "net_flow_top50": [
                    {
                        "rank": i + 1,
                        "address": addr,
                        "net_flow": flows['net_flow'],
                        "inflow": flows['inflow'],
                        "outflow": flows['outflow']
                    }
                    for i, (addr, flows) in enumerate(self.get_top_addresses('net_flow', 50))
                ],
                "net_outflow_top50": [
                    {
                        "rank": i + 1,
                        "address": addr,
                        "net_flow": flows['net_flow'],
                        "inflow": flows['inflow'],
                        "outflow": flows['outflow']
                    }
                    for i, (addr, flows) in enumerate(self.get_net_outflow_addresses(50))
                ],
                "inflow_top50": [
                    {
                        "rank": i + 1,
                        "address": addr,
                        "inflow": flows['inflow'],
                        "net_flow": flows['net_flow'],
                        "outflow": flows['outflow']
                    }
                    for i, (addr, flows) in enumerate(self.get_top_addresses('inflow', 50))
                ],
                "outflow_top50": [
                    {
                        "rank": i + 1,
                        "address": addr,
                        "outflow": flows['outflow'],
                        "net_flow": flows['net_flow'],
                        "inflow": flows['inflow']
                    }
                    for i, (addr, flows) in enumerate(self.get_top_addresses('outflow', 50))
                ]
            },
            "all_addresses": {
                addr: flows for addr, flows in self.address_flows.items()
            }
        }
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            print(f"\nğŸ’¾ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
            return output_file
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æŠ¥å‘Šæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    def print_summary(self):
        """æ‰“å°åˆ†ææ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“Š åˆ†ææ‘˜è¦")
        print("="*60)
        print(f"ğŸ“ æ•°æ®æ–‡ä»¶: {self.json_file_path}")
        print(f"ğŸ·ï¸  ä»£å¸åœ°å€: {self.token_info.get('address', 'N/A')}")
        print(f"ğŸ“ˆ æ€»äº¤æ˜“è®°å½•: {self.total_transactions:,}")
        print(f"ğŸ  æ¶‰åŠåœ°å€æ•°: {len(self.address_flows):,}")
        print(f"ğŸª™ æ€»äº¤æ˜“æ•°é‡: {self.total_volume:,.2f} ä»£å¸")
        
        # è®¡ç®—ä¸€äº›ç»Ÿè®¡æ•°æ®
        net_inflows = [f['net_flow'] for f in self.address_flows.values() if f['net_flow'] > 0]
        net_outflows = [f['net_flow'] for f in self.address_flows.values() if f['net_flow'] < 0]
        
        print(f"ğŸ“ˆ å‡€æµå…¥åœ°å€æ•°: {len(net_inflows):,}")
        print(f"ğŸ“‰ å‡€æµå‡ºåœ°å€æ•°: {len(net_outflows):,}")
        
        if net_inflows:
            print(f"ğŸ’ æœ€å¤§å‡€æµå…¥: {max(net_inflows):,.2f} ä»£å¸")
        if net_outflows:
            print(f"ğŸ’¸ æœ€å¤§å‡€æµå‡º: {abs(min(net_outflows)):,.2f} ä»£å¸")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='åˆ†æä»£å¸è½¬è´¦æ•°æ®ï¼Œè®¡ç®—åœ°å€å‡€æµå…¥å‡€æµå‡ºæ’è¡Œæ¦œ')
    parser.add_argument('json_file', help='è¾“å…¥çš„JSONæ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('-l', '--limit', type=int, default=20, help='æ˜¾ç¤ºæ’è¡Œæ¦œæ•°é‡é™åˆ¶ï¼ˆé»˜è®¤20ï¼‰')
    parser.add_argument('--no-save', action='store_true', help='ä¸ä¿å­˜åˆ†ææŠ¥å‘Š')
    
    args = parser.parse_args()
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = TokenFlowAnalyzer(args.json_file)
    
    # åŠ è½½æ•°æ®
    if not analyzer.load_data():
        return
    
    # æ‰§è¡Œåˆ†æ
    analyzer.analyze_flows()
    
    # æ˜¾ç¤ºæ‘˜è¦
    analyzer.print_summary()
    
    # æ˜¾ç¤ºæ’è¡Œæ¦œ
    analyzer.print_ranking('net_flow', args.limit)
    analyzer.print_ranking('net_outflow', args.limit)
    analyzer.print_ranking('inflow', args.limit)
    analyzer.print_ranking('outflow', args.limit)
    
    # ä¿å­˜æŠ¥å‘Š
    if not args.no_save:
        output_file = analyzer.save_analysis_report(args.output)
        if output_file:
            print(f"\nğŸ‰ åˆ†æå®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")


if __name__ == "__main__":
    # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤çš„æ•°æ®æ–‡ä»¶
    import sys
    if len(sys.argv) == 1:
        # æŸ¥æ‰¾æœ€æ–°çš„æ•°æ®æ–‡ä»¶
        storage_dir = "storage"
        if os.path.exists(storage_dir):
            json_files = [f for f in os.listdir(storage_dir) if f.startswith('solscan_data_') and f.endswith('.json')]
            if json_files:
                # æŒ‰æ–‡ä»¶åæ’åºï¼Œå–æœ€æ–°çš„
                latest_file = sorted(json_files)[-1]
                json_file_path = os.path.join(storage_dir, latest_file)
                
                print(f"ğŸ” æœªæŒ‡å®šè¾“å…¥æ–‡ä»¶ï¼Œä½¿ç”¨æœ€æ–°çš„æ•°æ®æ–‡ä»¶: {json_file_path}")
                
                analyzer = TokenFlowAnalyzer(json_file_path)
                if analyzer.load_data():
                    analyzer.analyze_flows()
                    analyzer.print_summary()
                    analyzer.print_ranking('net_flow', 20)
                    analyzer.print_ranking('net_outflow', 20)
                    analyzer.print_ranking('inflow', 20)
                    analyzer.print_ranking('outflow', 20)
                    analyzer.save_analysis_report()
                    print("\nğŸ‰ åˆ†æå®Œæˆï¼")
            else:
                print("âŒ storageç›®å½•ä¸­æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶")
        else:
            print("âŒ storageç›®å½•ä¸å­˜åœ¨")
    else:
        main()
