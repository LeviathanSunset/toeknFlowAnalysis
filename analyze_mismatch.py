#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æåœ°å€æ•°é‡ä¸åŒ¹é…é—®é¢˜
"""

import pandas as pd
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from analysis import TokenFlowAnalyzer

def analyze_address_count_mismatch():
    """åˆ†æåœ°å€æ•°é‡ä¸åŒ¹é…é—®é¢˜"""
    print("ğŸ” åˆ†æåœ°å€æ•°é‡ä¸åŒ¹é…é—®é¢˜")
    print("=" * 50)
    
    # åŠ è½½æ•°æ®
    analyzer = TokenFlowAnalyzer()
    analyzer.load_data("storage/solscan_data_20250901_142013.json")
    analyzer.analyze_net_flows()
    
    df = analyzer.net_flows_df
    
    # ç»Ÿè®¡æ‰€æœ‰åœ°å€
    total_addresses = len(df)
    net_inflow_addresses = len(df[df['net_tokens'] > 0])
    net_outflow_addresses = len(df[df['net_tokens'] < 0])
    zero_flow_addresses = len(df[df['net_tokens'] == 0])
    
    print(f"ğŸ“Š æ€»åœ°å€ç»Ÿè®¡:")
    print(f"   ğŸ  æ€»åœ°å€æ•°: {total_addresses}")
    print(f"   ğŸ“ˆ å‡€æµå…¥åœ°å€: {net_inflow_addresses}")
    print(f"   ğŸ“‰ å‡€æµå‡ºåœ°å€: {net_outflow_addresses}")
    print(f"   âš–ï¸ é›¶æµåŠ¨åœ°å€: {zero_flow_addresses}")
    print(f"   ğŸ§® å‡€æµå…¥+å‡€æµå‡º+é›¶æµåŠ¨: {net_inflow_addresses + net_outflow_addresses + zero_flow_addresses}")
    
    # è¿‡æ»¤çœŸå®äº¤æ˜“åœ°å€
    real_traders_df = df[df['address'].apply(analyzer._is_real_trader_address)]
    excluded_df = df[~df['address'].apply(analyzer._is_real_trader_address)]
    
    real_total = len(real_traders_df)
    real_inflow = len(real_traders_df[real_traders_df['net_tokens'] > 0])
    real_outflow = len(real_traders_df[real_traders_df['net_tokens'] < 0])
    real_zero = len(real_traders_df[real_traders_df['net_tokens'] == 0])
    
    print(f"\nğŸ“Š çœŸå®äº¤æ˜“åœ°å€ç»Ÿè®¡:")
    print(f"   âœ… çœŸå®äº¤æ˜“åœ°å€: {real_total}")
    print(f"   ğŸ“ˆ çœŸå®å‡€æµå…¥åœ°å€: {real_inflow}")
    print(f"   ğŸ“‰ çœŸå®å‡€æµå‡ºåœ°å€: {real_outflow}")
    print(f"   âš–ï¸ çœŸå®é›¶æµåŠ¨åœ°å€: {real_zero}")
    print(f"   ğŸ§® çœŸå®å‡€æµå…¥+å‡€æµå‡º+é›¶æµåŠ¨: {real_inflow + real_outflow + real_zero}")
    
    print(f"\nâŒ è¢«æ’é™¤åœ°å€: {len(excluded_df)}")
    
    # åˆ†æé›¶æµåŠ¨åœ°å€
    print(f"\nğŸ” é›¶æµåŠ¨åœ°å€è¯¦ç»†åˆ†æ:")
    zero_flow_df = df[df['net_tokens'] == 0]
    print(f"   æ€»é›¶æµåŠ¨åœ°å€: {len(zero_flow_df)}")
    
    for _, row in zero_flow_df.iterrows():
        address = row['address']
        label = analyzer.address_labels.get(address, "æ— æ ‡ç­¾")
        is_excluded = analyzer._is_excluded_address(address)
        status = "âŒè¢«æ’é™¤" if is_excluded else "âœ…çœŸå®äº¤æ˜“"
        print(f"   ğŸ“ {address[:8]}...{address[-6:]} - {label} - {status}")
        print(f"      å‡€æµåŠ¨: {row['net_tokens']}, æµå…¥: {row['inflow_tokens']:.2f}, æµå‡º: {row['outflow_tokens']:.2f}")
    
    print(f"\nğŸ’¡ ç»“è®º:")
    print(f"   å‡€æµå…¥åœ°å€({net_inflow_addresses}) + å‡€æµå‡ºåœ°å€({net_outflow_addresses}) = {net_inflow_addresses + net_outflow_addresses}")
    print(f"   çœŸå®äº¤æ˜“åœ°å€æ€»æ•°: {real_total}")
    print(f"   å·®å¼‚: {real_total - (net_inflow_addresses + net_outflow_addresses)} (è¿™äº›æ˜¯é›¶æµåŠ¨åœ°å€)")

if __name__ == "__main__":
    analyze_address_count_mismatch()
