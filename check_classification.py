#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€æŸ¥åœ°å€åˆ†ç±»é—®é¢˜
"""

import pandas as pd
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from analysis import TokenFlowAnalyzer

def check_classification_issues():
    """æ£€æŸ¥åœ°å€åˆ†ç±»é—®é¢˜"""
    print("ğŸ” æ£€æŸ¥åœ°å€åˆ†ç±»é—®é¢˜")
    print("=" * 50)
    
    # åŠ è½½æ•°æ®
    analyzer = TokenFlowAnalyzer()
    analyzer.load_data("storage/solscan_data_20250901_142013.json")
    analyzer.analyze_net_flows()
    
    df = analyzer.net_flows_df
    
    # æŸ¥æ‰¾0æµé‡è¢«åˆ†ç±»ä¸ºåšå¸‚å•†çš„æƒ…å†µ
    zero_flow_marketmakers = df[
        (df['net_tokens'] == 0) & 
        (df['address_type'].str.contains('åšå¸‚å•†|å¥—åˆ©è€…', na=False))
    ]
    
    print(f"ğŸš¨ å‘ç° {len(zero_flow_marketmakers)} ä¸ª0æµé‡è¢«åˆ†ç±»ä¸ºåšå¸‚å•†çš„åœ°å€:")
    for _, row in zero_flow_marketmakers.iterrows():
        address = row['address']
        label = analyzer.address_labels.get(address, "æ— æ ‡ç­¾")
        print(f"   ğŸ“ {address[:8]}...{address[-6:]} - {label} - {row['address_type']}")
        print(f"      å‡€æµåŠ¨: {row['net_tokens']}, æµå…¥: {row['inflow_tokens']}, æµå‡º: {row['outflow_tokens']}, äº¤æ˜“æ•°: {row['total_transactions']}")
    
    print()
    
    # æŸ¥æ‰¾æ‰€æœ‰çš„èšåˆå™¨ã€æ± å­ã€äº¤æ˜“æ‰€
    excluded_keywords = ['Exchange', 'Aggregator', 'AMM', 'Pool', 'Authority', 'CLMM', 'CPMM', 'DCA', 'Auction']
    excluded_addresses = []
    
    for address, label in analyzer.address_labels.items():
        if any(keyword in label for keyword in excluded_keywords):
            excluded_addresses.append(address)
    
    print(f"ğŸ¢ è¯†åˆ«åˆ° {len(excluded_addresses)} ä¸ªéœ€è¦æ’é™¤çš„åœ°å€ (èšåˆå™¨/æ± å­/äº¤æ˜“æ‰€):")
    for address in excluded_addresses:
        label = analyzer.address_labels[address]
        if address in df['address'].values:
            row = df[df['address'] == address].iloc[0]
            print(f"   ğŸ·ï¸ {label}")
            print(f"      åœ°å€: {address[:8]}...{address[-6:]}")
            print(f"      å‡€æµåŠ¨: {row['net_tokens']:.2f}, äº¤æ˜“æ•°: {row['total_transactions']}")
    
    print()
    
    # ç»Ÿè®¡å„ç±»å‹åœ°å€æ•°é‡
    print("ğŸ“Š åœ°å€ç±»å‹ç»Ÿè®¡:")
    type_counts = df['address_type'].value_counts()
    for addr_type, count in type_counts.items():
        print(f"   {addr_type}: {count} ä¸ª")

if __name__ == "__main__":
    check_classification_issues()
